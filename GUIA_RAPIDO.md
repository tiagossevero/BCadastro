# ğŸš€ Guia RÃ¡pido - Gerador de Data Schemas

## ğŸ“ Resumo

Gerar automaticamente **DESCRIBE FORMATTED** e **SELECT LIMIT 10** para **12 tabelas** do BCadastro.

---

## âš¡ ExecuÃ§Ã£o RÃ¡pida

### OpÃ§Ã£o 1: Script Python completo (Recomendado)

```bash
spark-submit gerar_data_schemas.py
```

### OpÃ§Ã£o 2: No Jupyter Notebook

Adicione uma nova cÃ©lula no `BCADASTRO-Exemplo.ipynb`:

```python
%run gerar_schemas_notebook.py
```

### OpÃ§Ã£o 3: Diretamente no PySpark shell

```python
exec(open('gerar_schemas_notebook.py').read())
```

---

## ğŸ“‹ Tabelas (12 total)

### âœ… 6 Originais

| # | Tabela | DescriÃ§Ã£o |
|---|--------|-----------|
| 1 | `bcadastro_base_cnpj_completo` | Base cadastral de empresas |
| 2 | `bcadastro_base_socios_consolidado` | Base de sÃ³cios |
| 3 | `bcadastro_pgdas_consolidado` | DeclaraÃ§Ãµes PGDAS |
| 4 | `bcadastro_tab_raiz_cpf_pai` | HistÃ³rico RBA por CPF |
| 5 | `feitoza_base_periodos_sn` | PerÃ­odos no Simples Nacional |
| 6 | `feitoza_rba_12_meses` | Receita Bruta Acumulada 12m |

### âœ… 6 IntermediÃ¡rias

| # | Tabela | DescriÃ§Ã£o |
|---|--------|-----------|
| 7 | `bcadastro_output_final_acl` | **Output principal** - Grupos irregulares |
| 8 | `feitoza_grupos_identificados` | Grupos econÃ´micos identificados |
| 9 | `feitoza_rba_grupo` | RBA consolidada por grupo |
| 10 | `feitoza_fato_gerador` | Fatos geradores de exclusÃ£o |
| 11 | `feitoza_resumo_grupos_irregulares` | Resumo grupos irregulares |
| 12 | `feitoza_lista_acao_fiscal` | Lista priorizada para fiscalizaÃ§Ã£o |

---

## ğŸ“ Output Gerado

```
data-schemas/
â”œâ”€â”€ README.md                                    # Ãndice geral
â”œâ”€â”€ originais/
â”‚   â”œâ”€â”€ bcadastro_base_cnpj_completo.md         # 6 arquivos .md
â”‚   â”œâ”€â”€ bcadastro_base_cnpj_completo.json       # 6 arquivos .json
â”‚   â””â”€â”€ ... (outras 5 tabelas)
â””â”€â”€ intermediarias/
    â”œâ”€â”€ bcadastro_output_final_acl.md           # 6 arquivos .md
    â”œâ”€â”€ bcadastro_output_final_acl.json         # 6 arquivos .json
    â””â”€â”€ ... (outras 5 tabelas)

Total: 25 arquivos (1 README + 12 MD + 12 JSON)
```

---

## ğŸ” Testar Manualmente

### Query individual (PySpark):

```python
# DESCRIBE FORMATTED
spark.sql("DESCRIBE FORMATTED gessimples.bcadastro_base_cnpj_completo").show(100, truncate=False)

# SELECT SAMPLE
spark.sql("SELECT * FROM gessimples.bcadastro_base_cnpj_completo LIMIT 10").show(truncate=False)
```

### Todas as queries de exemplo:

```bash
# Ver arquivo com todas as queries
cat queries_exemplo.sql
```

---

## ğŸ“Š ConteÃºdo dos Arquivos

Cada arquivo `.md` contÃ©m:

1. âœ… CabeÃ§alho (nome, tipo, database, data)
2. âœ… Estrutura da tabela (colunas + tipos)
3. âœ… Metadados (location, storage, etc.)
4. âœ… Dados de exemplo (10 linhas em tabela)
5. âœ… Queries SQL de referÃªncia

Cada arquivo `.json` contÃ©m:

- Dados estruturados do DESCRIBE FORMATTED
- Dados de exemplo (10 linhas)
- Metadados da geraÃ§Ã£o

---

## ğŸ› ï¸ PersonalizaÃ§Ã£o RÃ¡pida

### Alterar quantidade de linhas:

Edite o script e modifique:

```python
LIMIT 10  â†’  LIMIT 20
```

### Adicionar/remover tabelas:

Edite as listas:

```python
TABELAS_ORIGINAIS = [
    "sua_tabela_aqui",
    ...
]
```

### Alterar database:

```python
DATABASE = "gessimples"  â†’  DATABASE = "seu_db"
```

---

## ğŸ› Problemas Comuns

| Erro | SoluÃ§Ã£o |
|------|---------|
| `Table not found` | Verifique se a tabela existe: `SHOW TABLES IN gessimples;` |
| `Permission denied` | Verifique permissÃµes no banco |
| `Connection failed` | Teste conexÃ£o: `spark.sql("SHOW DATABASES").show()` |
| Arquivos nÃ£o gerados | Verifique logs de erro no console |

---

## âœ… Checklist

- [ ] PySpark instalado e configurado
- [ ] Acesso ao banco `gessimples`
- [ ] PermissÃµes de leitura nas tabelas
- [ ] Script executado com sucesso
- [ ] 25 arquivos gerados (1 README + 12 MD + 12 JSON)
- [ ] Dados de exemplo aparecem corretamente
- [ ] Commit dos arquivos no git

---

## ğŸ“š Arquivos Criados

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `gerar_data_schemas.py` | **Script principal** - Completo com JSON e MD |
| `gerar_schemas_notebook.py` | **VersÃ£o notebook** - Simplificada para Jupyter |
| `queries_exemplo.sql` | Queries individuais para teste manual |
| `INSTRUCOES_DATA_SCHEMAS.md` | DocumentaÃ§Ã£o completa |
| `GUIA_RAPIDO.md` | Este guia (referÃªncia rÃ¡pida) |

---

## ğŸ¯ PrÃ³ximos Passos

1. **Execute o script:**
   ```bash
   spark-submit gerar_data_schemas.py
   ```

2. **Revise os outputs:**
   ```bash
   ls -lh data-schemas/
   cat data-schemas/README.md
   ```

3. **Commit no git:**
   ```bash
   git add data-schemas/
   git commit -m "docs: adiciona data-schemas das tabelas"
   git push
   ```

---

## ğŸ’¡ Dicas

- ğŸš€ Execute em horÃ¡rio de baixo uso do cluster
- ğŸ“Š Verifique se todas as 12 tabelas foram processadas
- ğŸ” Revise os dados de exemplo para validar
- ğŸ“ Adicione comentÃ¡rios adicionais nos arquivos MD se necessÃ¡rio
- ğŸ”„ Re-execute periodicamente se os schemas mudarem

---

**Criado em:** 2025-11-17
**Database:** `gessimples` (Apache Impala)
**Total de tabelas:** 12 (6 originais + 6 intermediÃ¡rias)
