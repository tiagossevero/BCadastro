{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Gerador de Data Schemas - BCadastro\n",
    "\n",
    "Este notebook gera automaticamente a documenta√ß√£o completa dos schemas de todas as tabelas do projeto BCadastro.\n",
    "\n",
    "**Funcionalidades:**\n",
    "- Executa `DESCRIBE FORMATTED` para cada tabela\n",
    "- Executa `SELECT * FROM ... LIMIT 10` para dados de exemplo\n",
    "- Gera documenta√ß√£o em Markdown (.md)\n",
    "- Exporta dados estruturados em JSON (.json)\n",
    "- Organiza em diret√≥rios `originais/` e `intermediarias/`\n",
    "\n",
    "**Output esperado:** 25 arquivos (1 README + 12 MD + 12 JSON)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Configura√ß√£o Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necess√°rios\n",
    "import os\n",
    "import json\n",
    "import builtins  # IMPORTANTE: Para usar sum() nativo do Python sem conflito com pyspark.sql.functions.sum()\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Importa√ß√µes do PySpark (podem sobrescrever fun√ß√µes nativas)\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "print(\"‚úÖ Imports carregados com sucesso\")\n",
    "print(\"‚ö†Ô∏è  Nota: sum() do Python foi preservado via builtins.sum()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o\n",
    "DATABASE = \"gessimples\"\n",
    "OUTPUT_DIR = \"data-schemas\"\n",
    "\n",
    "# Lista de tabelas a serem documentadas\n",
    "TABELAS_ORIGINAIS = [\n",
    "    \"bcadastro_base_cnpj_completo\",\n",
    "    \"bcadastro_base_socios_consolidado\",\n",
    "    \"bcadastro_pgdas_consolidado\",\n",
    "    \"bcadastro_tab_raiz_cpf_pai\",\n",
    "    \"feitoza_base_periodos_sn\",\n",
    "    \"feitoza_rba_12_meses\"\n",
    "]\n",
    "\n",
    "TABELAS_INTERMEDIARIAS = [\n",
    "    \"bcadastro_output_final_acl\",\n",
    "    \"feitoza_grupos_identificados\",\n",
    "    \"feitoza_rba_grupo\",\n",
    "    \"feitoza_fato_gerador\",\n",
    "    \"feitoza_resumo_grupos_irregulares\",\n",
    "    \"feitoza_lista_acao_fiscal\"\n",
    "]\n",
    "\n",
    "print(f\"üìä Database: {DATABASE}\")\n",
    "print(f\"üìÅ Output: {OUTPUT_DIR}/\")\n",
    "print(f\"üìã Tabelas originais: {len(TABELAS_ORIGINAIS)}\")\n",
    "print(f\"üîÑ Tabelas intermedi√°rias: {len(TABELAS_INTERMEDIARIAS)}\")\n",
    "# Usar builtins.sum() ao inv√©s de sum() para evitar conflito com pyspark.sql.functions.sum()\n",
    "print(f\"üìä Total de tabelas: {builtins.sum([len(TABELAS_ORIGINAIS), len(TABELAS_INTERMEDIARIAS)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar estrutura de diret√≥rios\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/originais\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/intermediarias\", exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Estrutura de diret√≥rios criada:\")\n",
    "print(f\"   {OUTPUT_DIR}/\")\n",
    "print(f\"   {OUTPUT_DIR}/originais/\")\n",
    "print(f\"   {OUTPUT_DIR}/intermediarias/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_describe_formatted(tabela):\n",
    "    \"\"\"\n",
    "    Executa DESCRIBE FORMATTED e retorna os resultados\n",
    "    \n",
    "    Args:\n",
    "        tabela (str): Nome da tabela\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de dicion√°rios com col_name, data_type, comment\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = f\"DESCRIBE FORMATTED {DATABASE}.{tabela}\"\n",
    "        print(f\"  ‚ñ∂ Executando: {query}\")\n",
    "        df = spark.sql(query)\n",
    "        resultado = df.collect()\n",
    "        return [row.asDict() for row in resultado]\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Erro ao executar DESCRIBE FORMATTED em {tabela}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o executar_describe_formatted() definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_select_sample(tabela):\n",
    "    \"\"\"\n",
    "    Executa SELECT * LIMIT 10 e retorna os resultados\n",
    "    \n",
    "    Args:\n",
    "        tabela (str): Nome da tabela\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de dicion√°rios com os dados de exemplo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = f\"SELECT * FROM {DATABASE}.{tabela} LIMIT 10\"\n",
    "        print(f\"  ‚ñ∂ Executando: {query}\")\n",
    "        df = spark.sql(query)\n",
    "        resultado = df.collect()\n",
    "        \n",
    "        # Converter para dicion√°rio, tratando tipos especiais\n",
    "        data = []\n",
    "        for row in resultado:\n",
    "            row_dict = row.asDict()\n",
    "            # Converter valores n√£o serializ√°veis para string\n",
    "            for key, value in row_dict.items():\n",
    "                if value is not None and not isinstance(value, (str, int, float, bool, list, dict)):\n",
    "                    row_dict[key] = str(value)\n",
    "            data.append(row_dict)\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Erro ao executar SELECT em {tabela}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o executar_select_sample() definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_schema_markdown(tabela, tipo_tabela, describe_result, sample_data):\n",
    "    \"\"\"\n",
    "    Gera arquivo Markdown com o schema da tabela\n",
    "    \n",
    "    Args:\n",
    "        tabela (str): Nome da tabela\n",
    "        tipo_tabela (str): \"Original\" ou \"Intermedi√°ria\"\n",
    "        describe_result (list): Resultado do DESCRIBE FORMATTED\n",
    "        sample_data (list): Dados de exemplo\n",
    "    \n",
    "    Returns:\n",
    "        str: Conte√∫do do arquivo Markdown\n",
    "    \"\"\"\n",
    "    # Extrair informa√ß√µes do DESCRIBE FORMATTED\n",
    "    colunas = []\n",
    "    metadata = {}\n",
    "    secao_atual = None\n",
    "    \n",
    "    for row in describe_result:\n",
    "        col_name = row.get('col_name', '').strip()\n",
    "        data_type = row.get('data_type', '').strip()\n",
    "        comment = row.get('comment', '') or ''\n",
    "        \n",
    "        # Detectar se√ß√µes\n",
    "        if col_name.startswith('#'):\n",
    "            secao_atual = col_name\n",
    "            continue\n",
    "        \n",
    "        # Colunas da tabela\n",
    "        if col_name and data_type and secao_atual != '# Detailed Table Information':\n",
    "            if col_name not in ['', '# col_name']:\n",
    "                colunas.append({\n",
    "                    'nome': col_name,\n",
    "                    'tipo': data_type,\n",
    "                    'comentario': comment\n",
    "                })\n",
    "        \n",
    "        # Metadata da tabela\n",
    "        if secao_atual == '# Detailed Table Information' and col_name and data_type:\n",
    "            metadata[col_name] = data_type\n",
    "    \n",
    "    # Gerar conte√∫do Markdown\n",
    "    md_content = f\"\"\"# Data Schema: {tabela}\n",
    "\n",
    "**Tipo:** {tipo_tabela}\n",
    "**Database:** {DATABASE}\n",
    "**Gerado em:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Estrutura da Tabela\n",
    "\n",
    "### Colunas\n",
    "\n",
    "| Nome da Coluna | Tipo de Dado | Coment√°rio |\n",
    "|---------------|-------------|------------|\n",
    "\"\"\"\n",
    "    \n",
    "    for col in colunas:\n",
    "        comentario = col['comentario'] if col['comentario'] else '-'\n",
    "        md_content += f\"| `{col['nome']}` | `{col['tipo']}` | {comentario} |\\n\"\n",
    "    \n",
    "    # Adicionar metadata\n",
    "    md_content += \"\\n\\n### üîß Metadados da Tabela\\n\\n\"\n",
    "    md_content += \"| Propriedade | Valor |\\n\"\n",
    "    md_content += \"|------------|-------|\\n\"\n",
    "    \n",
    "    for key, value in metadata.items():\n",
    "        if key and value:\n",
    "            md_content += f\"| {key} | {value} |\\n\"\n",
    "    \n",
    "    # Adicionar dados de exemplo\n",
    "    md_content += \"\\n\\n---\\n\\n## üìä Dados de Exemplo (LIMIT 10)\\n\\n\"\n",
    "    \n",
    "    if sample_data and len(sample_data) > 0:\n",
    "        # Criar tabela markdown com os dados\n",
    "        headers = list(sample_data[0].keys())\n",
    "        md_content += \"| \" + \" | \".join(headers) + \" |\\n\"\n",
    "        md_content += \"|\" + \"|\".join([\"---\" for _ in headers]) + \"|\\n\"\n",
    "        \n",
    "        # Linhas de dados\n",
    "        for row in sample_data:\n",
    "            values = []\n",
    "            for header in headers:\n",
    "                value = row.get(header, '')\n",
    "                # Truncar valores muito longos\n",
    "                if value is not None:\n",
    "                    value_str = str(value)\n",
    "                    if len(value_str) > 50:\n",
    "                        value_str = value_str[:47] + \"...\"\n",
    "                    values.append(value_str)\n",
    "                else:\n",
    "                    values.append(\"NULL\")\n",
    "            md_content += \"| \" + \" | \".join(values) + \" |\\n\"\n",
    "    else:\n",
    "        md_content += \"*Nenhum dado dispon√≠vel*\\n\"\n",
    "    \n",
    "    # Adicionar query SQL\n",
    "    md_content += f\"\\n\\n---\\n\\n## üîç Queries de Refer√™ncia\\n\\n\"\n",
    "    md_content += f\"### Describe Formatted\\n\\n```sql\\nDESCRIBE FORMATTED {DATABASE}.{tabela};\\n```\\n\\n\"\n",
    "    md_content += f\"### Select Sample\\n\\n```sql\\nSELECT * FROM {DATABASE}.{tabela} LIMIT 10;\\n```\\n\"\n",
    "    \n",
    "    return md_content\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o gerar_schema_markdown() definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_schema_json(tabela, describe_result, sample_data):\n",
    "    \"\"\"\n",
    "    Gera arquivo JSON com o schema da tabela\n",
    "    \n",
    "    Args:\n",
    "        tabela (str): Nome da tabela\n",
    "        describe_result (list): Resultado do DESCRIBE FORMATTED\n",
    "        sample_data (list): Dados de exemplo\n",
    "    \n",
    "    Returns:\n",
    "        str: Conte√∫do do arquivo JSON\n",
    "    \"\"\"\n",
    "    schema_json = {\n",
    "        \"tabela\": tabela,\n",
    "        \"database\": DATABASE,\n",
    "        \"gerado_em\": datetime.now().isoformat(),\n",
    "        \"describe_formatted\": describe_result,\n",
    "        \"sample_data\": sample_data\n",
    "    }\n",
    "    return json.dumps(schema_json, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o gerar_schema_json() definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_tabela(tabela, tipo_tabela):\n",
    "    \"\"\"\n",
    "    Processa uma tabela e gera os arquivos de schema\n",
    "    \n",
    "    Args:\n",
    "        tabela (str): Nome da tabela\n",
    "        tipo_tabela (str): \"Original\" ou \"Intermedi√°ria\"\n",
    "    \n",
    "    Returns:\n",
    "        bool: True se sucesso, False se erro\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìã Processando: {DATABASE}.{tabela}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Executar queries\n",
    "    describe_result = executar_describe_formatted(tabela)\n",
    "    sample_data = executar_select_sample(tabela)\n",
    "    \n",
    "    if describe_result is None:\n",
    "        print(f\"  ‚ö†Ô∏è  Pulando {tabela} - Erro no DESCRIBE FORMATTED\")\n",
    "        return False\n",
    "    \n",
    "    # Determinar diret√≥rio de sa√≠da\n",
    "    subdir = \"originais\" if tipo_tabela == \"Original\" else \"intermediarias\"\n",
    "    \n",
    "    # Gerar e salvar Markdown\n",
    "    md_content = gerar_schema_markdown(tabela, tipo_tabela, describe_result, sample_data)\n",
    "    md_file = f\"{OUTPUT_DIR}/{subdir}/{tabela}.md\"\n",
    "    with open(md_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(md_content)\n",
    "    print(f\"  ‚úÖ Markdown salvo em: {md_file}\")\n",
    "    \n",
    "    # Gerar e salvar JSON\n",
    "    json_content = gerar_schema_json(tabela, describe_result, sample_data)\n",
    "    json_file = f\"{OUTPUT_DIR}/{subdir}/{tabela}.json\"\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(json_content)\n",
    "    print(f\"  ‚úÖ JSON salvo em: {json_file}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o processar_tabela() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Processamento das Tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabe√ßalho\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ GERADOR DE DATA SCHEMAS - BCadastro\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Database: {DATABASE}\")\n",
    "# Usar builtins.sum() para evitar conflito com pyspark.sql.functions.sum()\n",
    "total_tabelas = builtins.sum([len(TABELAS_ORIGINAIS), len(TABELAS_INTERMEDIARIAS)])\n",
    "print(f\"Total de tabelas: {total_tabelas}\")\n",
    "print(f\"Output: {OUTPUT_DIR}/\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶ Processando Tabelas Originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sucesso = 0\n",
    "falha = 0\n",
    "\n",
    "print(\"\\n\\nüì¶ PROCESSANDO TABELAS ORIGINAIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for tabela in TABELAS_ORIGINAIS:\n",
    "    if processar_tabela(tabela, \"Original\"):\n",
    "        sucesso += 1\n",
    "    else:\n",
    "        falha += 1\n",
    "\n",
    "print(f\"\\n‚úÖ Tabelas originais processadas: {sucesso}/{len(TABELAS_ORIGINAIS)}\")\n",
    "if falha > 0:\n",
    "    print(f\"‚ùå Falhas: {falha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Processando Tabelas Intermedi√°rias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nüîÑ PROCESSANDO TABELAS INTERMEDI√ÅRIAS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for tabela in TABELAS_INTERMEDIARIAS:\n",
    "    if processar_tabela(tabela, \"Intermedi√°ria\"):\n",
    "        sucesso += 1\n",
    "    else:\n",
    "        falha += 1\n",
    "\n",
    "print(f\"\\n‚úÖ Tabelas intermedi√°rias processadas: {len(TABELAS_INTERMEDIARIAS) - (falha - (len(TABELAS_ORIGINAIS) - sucesso))}/{len(TABELAS_INTERMEDIARIAS)}\")\n",
    "if falha > 0:\n",
    "    print(f\"‚ùå Falhas totais: {falha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìë Gerando √çndice Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nüìë GERANDO √çNDICE GERAL\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Calcular total usando builtins.sum()\n",
    "total_tabelas = builtins.sum([len(TABELAS_ORIGINAIS), len(TABELAS_INTERMEDIARIAS)])\n",
    "\n",
    "index_content = f\"\"\"# Data Schemas - BCadastro\n",
    "\n",
    "**Database:** {DATABASE}\n",
    "**Gerado em:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Total de tabelas:** {total_tabelas}\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Tabelas Originais ({len(TABELAS_ORIGINAIS)})\n",
    "\n",
    "Tabelas fonte de dados do banco de dados:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for tabela in TABELAS_ORIGINAIS:\n",
    "    index_content += f\"- [{tabela}](originais/{tabela}.md)\\n\"\n",
    "\n",
    "index_content += f\"\\n\\n## üîÑ Tabelas Intermedi√°rias ({len(TABELAS_INTERMEDIARIAS)})\\n\\n\"\n",
    "index_content += \"Tabelas criadas pelo processo de ETL:\\n\\n\"\n",
    "\n",
    "for tabela in TABELAS_INTERMEDIARIAS:\n",
    "    index_content += f\"- [{tabela}](intermediarias/{tabela}.md)\\n\"\n",
    "\n",
    "index_content += f\"\"\"\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Estat√≠sticas\n",
    "\n",
    "- ‚úÖ Processadas com sucesso: {sucesso}\n",
    "- ‚ùå Falhas: {falha}\n",
    "- üìÅ Total de arquivos gerados: {sucesso * 2} (Markdown + JSON)\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Estrutura de Diret√≥rios\n",
    "\n",
    "```\n",
    "data-schemas/\n",
    "‚îú‚îÄ‚îÄ README.md (este arquivo)\n",
    "‚îú‚îÄ‚îÄ originais/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ *.md (schemas em Markdown)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ *.json (schemas em JSON)\n",
    "‚îî‚îÄ‚îÄ intermediarias/\n",
    "    ‚îú‚îÄ‚îÄ *.md (schemas em Markdown)\n",
    "    ‚îî‚îÄ‚îÄ *.json (schemas em JSON)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Gerado automaticamente por:** `gerar_data_schemas.ipynb`\n",
    "\"\"\"\n",
    "\n",
    "readme_file = f\"{OUTPUT_DIR}/README.md\"\n",
    "with open(readme_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(index_content)\n",
    "print(f\"‚úÖ √çndice salvo em: {readme_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ú® Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo final\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"‚ú® PROCESSAMENTO CONCLU√çDO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calcular total usando builtins.sum()\n",
    "total_esperado = builtins.sum([len(TABELAS_ORIGINAIS), len(TABELAS_INTERMEDIARIAS)])\n",
    "\n",
    "print(f\"‚úÖ Sucesso: {sucesso}/{total_esperado}\")\n",
    "print(f\"‚ùå Falhas: {falha}/{total_esperado}\")\n",
    "print(f\"üìÅ Arquivos gerados: {sucesso * 2} (Markdown + JSON)\")\n",
    "print(f\"üìÇ Diret√≥rio de sa√≠da: {OUTPUT_DIR}/\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Estat√≠sticas detalhadas\n",
    "print(\"\\nüìä Estat√≠sticas detalhadas:\")\n",
    "print(f\"  - Tabelas originais processadas: {builtins.sum([1 for t in TABELAS_ORIGINAIS])}/{len(TABELAS_ORIGINAIS)}\")\n",
    "print(f\"  - Tabelas intermedi√°rias processadas: {builtins.sum([1 for t in TABELAS_INTERMEDIARIAS])}/{len(TABELAS_INTERMEDIARIAS)}\")\n",
    "print(f\"  - Taxa de sucesso: {(sucesso/total_esperado*100):.1f}%\")\n",
    "\n",
    "if sucesso == total_esperado:\n",
    "    print(\"\\nüéâ TODOS OS DATA-SCHEMAS FORAM GERADOS COM SUCESSO!\")\n",
    "    print(\"\\nPr√≥ximos passos:\")\n",
    "    print(\"  1. Revisar os arquivos em: data-schemas/\")\n",
    "    print(\"  2. git add data-schemas/\")\n",
    "    print(\"  3. git commit -m 'docs: adiciona data-schemas das tabelas'\")\n",
    "    print(\"  4. git push\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  ATEN√á√ÉO: Algumas tabelas n√£o foram processadas.\")\n",
    "    print(\"   Verifique os erros acima e tente novamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
