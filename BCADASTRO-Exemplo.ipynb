{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aea681-2477-45f5-9ffe-1cb8f6cb1a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/poc\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/plugins\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/dags\")\n",
    "\n",
    "#Import libs python\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import date\n",
    "\n",
    "#Import libs internas\n",
    "from utils import spark_utils_session as utils\n",
    "\n",
    "from hooks.hdfs.hdfs_helper import HdfsHelper\n",
    "from jobs.job_base_config import BaseETLJobClass\n",
    "\n",
    "import poc_helper\n",
    "poc_helper.load_env(\"PROD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf8a1f-48e4-4c57-a162-c839c8e3a940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_session(profile: str, dynamic_allocation_enabled: bool = True) -> utils.DBASparkAppSession:\n",
    "    \"\"\"Generates DBASparkAppSession.\"\"\"\n",
    "    \n",
    "    app_name = \"tsevero_bcadastro\"\n",
    "    \n",
    "    spark_builder = (utils.DBASparkAppSession\n",
    "                     .builder\n",
    "                     .setAppName(app_name)\n",
    "                     .usingProcessProfile(profile)\n",
    "                    )\n",
    "    \n",
    "    if dynamic_allocation_enabled:\n",
    "        spark_builder.autoResourceManagement()\n",
    "\n",
    "    return spark_builder.build()\n",
    "\n",
    "session = get_session(profile='efd_t2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00777b24-69dc-4a6e-ba6f-4e11cd534937",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sparkSession.sql(\"SHOW DATABASES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2b5ea-0ad8-4662-9b4d-3fb7ef933060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURA√á√ÉO INICIAL - PROJETO SIMPLES NACIONAL E GRUPOS ECON√îMICOS\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# PySpark imports com aliases para evitar conflitos\n",
    "from pyspark.sql.functions import (\n",
    "    col as spark_col, \n",
    "    sum as spark_sum, \n",
    "    avg as spark_avg,\n",
    "    count as spark_count,\n",
    "    when as spark_when,\n",
    "    desc as spark_desc,\n",
    "    asc as spark_asc,\n",
    "    round as spark_round,\n",
    "    concat as spark_concat,\n",
    "    lit as spark_lit,\n",
    "    max as spark_max,\n",
    "    min as spark_min,\n",
    "    stddev as spark_stddev,\n",
    "    countDistinct as spark_countDistinct\n",
    ")\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Acesso ao Spark\n",
    "spark = session.sparkSession\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üîç SISTEMA DE AN√ÅLISE - SIMPLES NACIONAL E GRUPOS ECON√îMICOS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Sess√£o Spark: {spark.sparkContext.appName}\")\n",
    "print(f\"Vers√£o Spark: {spark.version}\")\n",
    "print(f\"Iniciado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53aacaa-ce73-4cc7-850d-b833b00b7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PANORAMA GERAL DO SISTEMA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä VERIFICA√á√ÉO DE TABELAS E ESTAT√çSTICAS GERAIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Lista de tabelas do projeto\n",
    "tabelas_projeto = [\n",
    "    'gessimples.feitoza_base_cnpj_completo',\n",
    "    'gessimples.feitoza_base_socios_consolidado',\n",
    "    'gessimples.feitoza_base_periodos_sn',\n",
    "    'gessimples.feitoza_pgdas_consolidado',\n",
    "    'gessimples.feitoza_rba_12_meses',\n",
    "    'gessimples.feitoza_grupos_identificados',\n",
    "    'gessimples.feitoza_rba_grupo',\n",
    "    'gessimples.feitoza_fato_gerador',\n",
    "    'gessimples.feitoza_resumo_grupos_irregulares',\n",
    "    'gessimples.feitoza_lista_acao_fiscal'\n",
    "]\n",
    "\n",
    "print(\"\\nüìã Verificando exist√™ncia e tamanho das tabelas:\\n\")\n",
    "tabelas_info = []\n",
    "for tabela in tabelas_projeto:\n",
    "    try:\n",
    "        count = spark.sql(f\"SELECT COUNT(*) as cnt FROM {tabela}\").collect()[0]['cnt']\n",
    "        print(f\"‚úÖ {tabela:50s} ‚Üí {count:>12,} registros\")\n",
    "        tabelas_info.append({'tabela': tabela, 'registros': count, 'status': 'OK'})\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {tabela:50s} ‚Üí N√ÉO ENCONTRADA\")\n",
    "        tabelas_info.append({'tabela': tabela, 'registros': 0, 'status': 'ERRO'})\n",
    "\n",
    "# Converter para DataFrame para an√°lise\n",
    "df_tabelas_info = pd.DataFrame(tabelas_info)\n",
    "print(f\"\\n‚úÖ Total de tabelas verificadas: {len(df_tabelas_info)}\")\n",
    "print(f\"‚úÖ Tabelas dispon√≠veis: {(df_tabelas_info['status'] == 'OK').sum()}\")\n",
    "print(f\"‚ùå Tabelas com erro: {(df_tabelas_info['status'] == 'ERRO').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e0ab4-4a99-4b20-a18c-57ee4c628e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ESTAT√çSTICAS GERAIS DO SISTEMA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìà ESTAT√çSTICAS GERAIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Criar view com estat√≠sticas consolidadas\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_stats_geral AS\n",
    "SELECT \n",
    "    COUNT(DISTINCT bc.cnpj_raiz) AS total_empresas,\n",
    "    COUNT(DISTINCT CASE WHEN bc.uf = 'SC' THEN bc.cnpj_raiz END) AS empresas_sc,\n",
    "    COUNT(DISTINCT CASE WHEN psn.cnpj_raiz IS NOT NULL THEN bc.cnpj_raiz END) AS empresas_sn,\n",
    "    COUNT(DISTINCT sc.cpf_socio) AS total_socios,\n",
    "    COUNT(DISTINCT CASE WHEN gi.num_grupo IS NOT NULL THEN sc.cpf_socio END) AS socios_em_grupos,\n",
    "    COUNT(DISTINCT gi.num_grupo) AS total_grupos,\n",
    "    COUNT(DISTINCT CASE WHEN gi.tipo_grupo = 'GRUPO_SC_PURO' THEN gi.num_grupo END) AS grupos_sc_puro,\n",
    "    COUNT(DISTINCT rgi.num_grupo) AS grupos_irregulares,\n",
    "    CAST(COALESCE(SUM(rba.vl_rba_12_meses), 0) AS DOUBLE) AS rba_total,\n",
    "    CAST(COALESCE(AVG(rba.vl_rba_12_meses), 0) AS DOUBLE) AS rba_media,\n",
    "    CAST(COALESCE(MAX(rba.vl_rba_12_meses), 0) AS DOUBLE) AS rba_maxima\n",
    "FROM gessimples.feitoza_base_cnpj_completo bc\n",
    "LEFT JOIN gessimples.feitoza_base_socios_consolidado sc ON bc.cnpj_raiz = sc.cnpj_raiz\n",
    "LEFT JOIN gessimples.feitoza_base_periodos_sn psn ON bc.cnpj_raiz = psn.cnpj_raiz\n",
    "LEFT JOIN gessimples.feitoza_grupos_identificados gi ON sc.cpf_socio = gi.cpf_socio\n",
    "LEFT JOIN gessimples.feitoza_resumo_grupos_irregulares rgi ON gi.num_grupo = rgi.num_grupo\n",
    "LEFT JOIN gessimples.feitoza_rba_12_meses rba ON bc.cnpj_raiz = rba.cnpj_raiz\n",
    "\"\"\")\n",
    "\n",
    "# Verificar tamanho\n",
    "total_stats = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_stats_geral\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de registros nas estat√≠sticas: {total_stats}\")\n",
    "\n",
    "if total_stats > 0:\n",
    "    df_stats = spark.sql(\"SELECT * FROM vw_stats_geral\").toPandas()\n",
    "    \n",
    "    s = df_stats.iloc[0]\n",
    "    \n",
    "    print(\"\\nüéØ M√âTRICAS PRINCIPAIS:\")\n",
    "    print(f\"  ‚Ä¢ Total de Empresas Analisadas: {int(s['total_empresas']):,}\")\n",
    "    print(f\"  ‚Ä¢ Empresas em SC: {int(s['empresas_sc']):,}\")\n",
    "    print(f\"  ‚Ä¢ Empresas do Simples Nacional: {int(s['empresas_sn']):,}\")\n",
    "    print(f\"  ‚Ä¢ Total de S√≥cios √önicos: {int(s['total_socios']):,}\")\n",
    "    print(f\"  ‚Ä¢ S√≥cios em Grupos Econ√¥micos: {int(s['socios_em_grupos']):,}\")\n",
    "    \n",
    "    print(f\"\\nüè¢ GRUPOS ECON√îMICOS:\")\n",
    "    print(f\"  ‚Ä¢ Total de Grupos Identificados: {int(s['total_grupos']):,}\")\n",
    "    print(f\"  ‚Ä¢ Grupos SC Puro: {int(s['grupos_sc_puro']):,}\")\n",
    "    print(f\"  ‚Ä¢ Grupos Irregulares: {int(s['grupos_irregulares']):,}\")\n",
    "    \n",
    "    print(f\"\\nüí∞ RECEITA BRUTA ACUMULADA (RBA):\")\n",
    "    print(f\"  ‚Ä¢ RBA Total: R$ {s['rba_total']:,.2f}\")\n",
    "    print(f\"  ‚Ä¢ RBA M√©dia por Empresa: R$ {s['rba_media']:,.2f}\")\n",
    "    print(f\"  ‚Ä¢ RBA M√°xima: R$ {s['rba_maxima']:,.2f}\")\n",
    "    \n",
    "    # Percentuais\n",
    "    if s['total_empresas'] > 0:\n",
    "        perc_sn = (s['empresas_sn'] / s['total_empresas']) * 100\n",
    "        perc_irregulares = (s['grupos_irregulares'] / s['total_grupos']) * 100 if s['total_grupos'] > 0 else 0\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  INDICADORES DE RISCO:\")\n",
    "        print(f\"  ‚Ä¢ {perc_sn:.1f}% das empresas s√£o optantes do SN\")\n",
    "        print(f\"  ‚Ä¢ {perc_irregulares:.1f}% dos grupos est√£o irregulares\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum dado encontrado nas estat√≠sticas gerais\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00868a-e0b0-442b-9e8e-1856d0796a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DISTRIBUI√á√ÉO DE EMPRESAS POR SITUA√á√ÉO CADASTRAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä DISTRIBUI√á√ÉO POR SITUA√á√ÉO CADASTRAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Criar view\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_situacao_cadastral AS\n",
    "SELECT \n",
    "    situacao_cadastral_desc,\n",
    "    COUNT(DISTINCT cnpj_raiz) AS qtd_empresas,\n",
    "    COUNT(DISTINCT CASE WHEN uf = 'SC' THEN cnpj_raiz END) AS qtd_sc\n",
    "FROM gessimples.feitoza_base_cnpj_completo\n",
    "GROUP BY situacao_cadastral_desc\n",
    "ORDER BY qtd_empresas DESC\n",
    "\"\"\")\n",
    "\n",
    "# Verificar tamanho\n",
    "total_sit = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_situacao_cadastral\").collect()[0]['cnt']\n",
    "\n",
    "if total_sit > 0 and total_sit <= 20:\n",
    "    df_situacao = spark.sql(\"SELECT * FROM vw_situacao_cadastral\").toPandas()\n",
    "    \n",
    "    print(f\"\\nüìã Distribui√ß√£o por Situa√ß√£o Cadastral:\\n\")\n",
    "    for idx, row in df_situacao.iterrows():\n",
    "        perc_sc = (row['qtd_sc'] / row['qtd_empresas']) * 100 if row['qtd_empresas'] > 0 else 0\n",
    "        print(f\"  {row['situacao_cadastral_desc']:15s} ‚Üí {int(row['qtd_empresas']):>7,} empresas \"\n",
    "              f\"({int(row['qtd_sc']):>6,} SC - {perc_sc:.1f}%)\")\n",
    "    \n",
    "    # Gr√°fico de Pizza\n",
    "    fig_situacao = go.Figure(data=[go.Pie(\n",
    "        labels=df_situacao['situacao_cadastral_desc'],\n",
    "        values=df_situacao['qtd_empresas'],\n",
    "        hole=0.4,\n",
    "        marker=dict(colors=['#2ca02c', '#ffdd70', '#ff7f0e', '#d62728', '#9467bd']),\n",
    "        textinfo='label+percent+value',\n",
    "        texttemplate='<b>%{label}</b><br>%{value:,}<br>%{percent:.1%}'\n",
    "    )])\n",
    "    \n",
    "    fig_situacao.update_layout(\n",
    "        title='<b>Distribui√ß√£o de Empresas por Situa√ß√£o Cadastral</b>',\n",
    "        height=500,\n",
    "        showlegend=True,\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "    \n",
    "    fig_situacao.show()\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Dados de situa√ß√£o cadastral n√£o dispon√≠veis ou muito fragmentados ({total_sit} categorias)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a80b3-f6d4-4687-be55-f8fff33db992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AN√ÅLISE GEOGR√ÅFICA - DISTRIBUI√á√ÉO POR UF\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üó∫Ô∏è  AN√ÅLISE GEOGR√ÅFICA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ‚úÖ CORRE√á√ÉO: Usar apenas √∫ltimo per√≠odo dispon√≠vel + aliases expl√≠citos\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_geografica_uf AS\n",
    "SELECT \n",
    "    bc.uf,\n",
    "    COUNT(DISTINCT bc.cnpj_raiz) AS total_empresas,\n",
    "    COUNT(DISTINCT CASE WHEN psn.cnpj_raiz IS NOT NULL THEN bc.cnpj_raiz END) AS empresas_sn,\n",
    "    COUNT(DISTINCT CASE WHEN bc.situacao_cadastral_desc = 'ATIVA' THEN bc.cnpj_raiz END) AS empresas_ativas,\n",
    "    CAST(COALESCE(AVG(rba_ult.vl_rba_12_meses), 0) AS DOUBLE) AS rba_media,\n",
    "    CAST(COALESCE(SUM(rba_ult.vl_rba_12_meses), 0) AS DOUBLE) AS rba_total,\n",
    "    COUNT(DISTINCT rba_ult.cnpj_raiz) AS empresas_com_rba\n",
    "FROM gessimples.feitoza_base_cnpj_completo bc\n",
    "LEFT JOIN gessimples.feitoza_base_periodos_sn psn \n",
    "    ON bc.cnpj_raiz = psn.cnpj_raiz\n",
    "LEFT JOIN (\n",
    "    -- ‚úÖ Subquery: pegar APENAS √∫ltimo per√≠odo de cada empresa\n",
    "    SELECT \n",
    "        cnpj_raiz,\n",
    "        vl_rba_12_meses,\n",
    "        periodo_apuracao\n",
    "    FROM (\n",
    "        SELECT \n",
    "            cnpj_raiz,\n",
    "            vl_rba_12_meses,\n",
    "            periodo_apuracao,\n",
    "            ROW_NUMBER() OVER (PARTITION BY cnpj_raiz ORDER BY periodo_apuracao DESC) AS rn\n",
    "        FROM gessimples.feitoza_rba_12_meses\n",
    "        WHERE periodo_apuracao >= 202409  -- √öltimos meses com dados completos\n",
    "    ) ranked\n",
    "    WHERE rn = 1\n",
    ") rba_ult ON bc.cnpj_raiz = rba_ult.cnpj_raiz\n",
    "WHERE bc.uf IS NOT NULL \n",
    "  AND bc.uf != ''\n",
    "  AND LENGTH(bc.uf) = 2  -- ‚úÖ Apenas siglas v√°lidas (exclui \"EX\")\n",
    "GROUP BY bc.uf\n",
    "ORDER BY total_empresas DESC\n",
    "\"\"\")\n",
    "\n",
    "total_uf = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_geografica_uf\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de UFs encontradas: {total_uf}\")\n",
    "\n",
    "# ‚úÖ CORRE√á√ÉO: Aceitar at√© 30 UFs (mais flex√≠vel)\n",
    "if total_uf > 0 and total_uf <= 30:\n",
    "    df_uf = spark.sql(\"SELECT * FROM vw_geografica_uf\").toPandas()\n",
    "    \n",
    "    print(f\"\\nüèõÔ∏è DISTRIBUI√á√ÉO POR ESTADO (Top 15):\\n\")\n",
    "    for idx, row in df_uf.head(15).iterrows():\n",
    "        perc_sn = (row['empresas_sn'] / row['total_empresas']) * 100 if row['total_empresas'] > 0 else 0\n",
    "        perc_ativas = (row['empresas_ativas'] / row['total_empresas']) * 100 if row['total_empresas'] > 0 else 0\n",
    "        print(f\"  {row['uf']:2s} ‚Üí {int(row['total_empresas']):>7,} empresas | \"\n",
    "              f\"SN: {int(row['empresas_sn']):>6,} ({perc_sn:>5.1f}%) | \"\n",
    "              f\"Ativas: {perc_ativas:>5.1f}% | \"\n",
    "              f\"RBA M√©dia: R$ {row['rba_media']:>12,.2f}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO 1: Barras Empilhadas - SN vs Outros Regimes\n",
    "    # ========================================================================\n",
    "    \n",
    "    df_uf_top15 = df_uf.head(15).sort_values('total_empresas', ascending=True)\n",
    "    \n",
    "    fig_uf = go.Figure()\n",
    "    \n",
    "    fig_uf.add_trace(go.Bar(\n",
    "        y=df_uf_top15['uf'],\n",
    "        x=df_uf_top15['empresas_sn'],\n",
    "        name='Simples Nacional',\n",
    "        orientation='h',\n",
    "        marker=dict(color='#2ca02c'),\n",
    "        text=df_uf_top15['empresas_sn'].apply(lambda x: f'{int(x):,}' if x > 0 else ''),\n",
    "        textposition='inside',\n",
    "        hovertemplate='<b>SN:</b> %{x:,}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig_uf.add_trace(go.Bar(\n",
    "        y=df_uf_top15['uf'],\n",
    "        x=df_uf_top15['total_empresas'] - df_uf_top15['empresas_sn'],\n",
    "        name='Outros Regimes',\n",
    "        orientation='h',\n",
    "        marker=dict(color='#1f77b4'),\n",
    "        text=(df_uf_top15['total_empresas'] - df_uf_top15['empresas_sn']).apply(lambda x: f'{int(x):,}' if x > 0 else ''),\n",
    "        textposition='inside',\n",
    "        hovertemplate='<b>Outros:</b> %{x:,}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig_uf.update_layout(\n",
    "        title='<b>Top 15 Estados - Empresas por Regime Tribut√°rio</b>',\n",
    "        xaxis_title='Quantidade de Empresas',\n",
    "        yaxis_title='UF',\n",
    "        barmode='stack',\n",
    "        height=600,\n",
    "        showlegend=True,\n",
    "        hovermode='y unified'\n",
    "    )\n",
    "    \n",
    "    fig_uf.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO 2: Barras - RBA Total por UF\n",
    "    # ========================================================================\n",
    "    \n",
    "    df_uf_rba = df_uf[df_uf['rba_total'] > 0].head(15).sort_values('rba_total', ascending=True)\n",
    "    \n",
    "    if len(df_uf_rba) > 0:\n",
    "        print(f\"\\nüí∞ TOP 15 ESTADOS POR RBA TOTAL:\\n\")\n",
    "        for idx, row in df_uf_rba.sort_values('rba_total', ascending=False).iterrows():\n",
    "            print(f\"  {row['uf']:2s} ‚Üí RBA Total: R$ {row['rba_total']:>15,.2f} | \"\n",
    "                  f\"Empresas com RBA: {int(row['empresas_com_rba']):>6,}\")\n",
    "        \n",
    "        fig_rba_uf = go.Figure(go.Bar(\n",
    "            y=df_uf_rba['uf'],\n",
    "            x=df_uf_rba['rba_total'] / 1e9,\n",
    "            orientation='h',\n",
    "            marker=dict(\n",
    "                color=df_uf_rba['rba_media'],\n",
    "                colorscale='Viridis',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"RBA M√©dia<br>(R$)\")\n",
    "            ),\n",
    "            text=df_uf_rba['rba_total'].apply(lambda x: f'R$ {x/1e9:.1f}B'),\n",
    "            textposition='outside',\n",
    "            hovertemplate='<b>%{y}</b><br>RBA Total: R$ %{x:.2f}B<br>Empresas com RBA: %{customdata:,}<extra></extra>',\n",
    "            customdata=df_uf_rba['empresas_com_rba']\n",
    "        ))\n",
    "        \n",
    "        fig_rba_uf.update_layout(\n",
    "            title='<b>RBA Total por Estado (Bilh√µes R$)</b>',\n",
    "            xaxis_title='RBA Total (Bilh√µes R$)',\n",
    "            yaxis_title='UF',\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        fig_rba_uf.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO 3: Pizza - Empresas Ativas vs Inativas\n",
    "    # ========================================================================\n",
    "    \n",
    "    total_ativas = df_uf['empresas_ativas'].sum()\n",
    "    total_geral = df_uf['total_empresas'].sum()\n",
    "    total_inativas = total_geral - total_ativas\n",
    "    \n",
    "    fig_situacao = go.Figure(data=[go.Pie(\n",
    "        labels=['Empresas Ativas', 'Empresas Inativas'],\n",
    "        values=[total_ativas, total_inativas],\n",
    "        hole=0.4,\n",
    "        marker=dict(colors=['#2ca02c', '#d62728']),\n",
    "        textinfo='label+percent+value',\n",
    "        texttemplate='<b>%{label}</b><br>%{value:,}<br>%{percent:.1%}'\n",
    "    )])\n",
    "    \n",
    "    fig_situacao.update_layout(\n",
    "        title='<b>Distribui√ß√£o: Empresas Ativas vs Inativas</b>',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig_situacao.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICO 4: Mapa de Calor - RBA M√©dia\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Filtrar apenas UFs do Brasil (excluir EX se existir)\n",
    "    df_uf_mapa = df_uf[df_uf['uf'] != 'EX']\n",
    "    \n",
    "    if len(df_uf_mapa) > 0:\n",
    "        fig_mapa = go.Figure(data=go.Choropleth(\n",
    "            locations=df_uf_mapa['uf'],\n",
    "            z=df_uf_mapa['rba_media'],\n",
    "            locationmode='USA-states',\n",
    "            colorscale='Viridis',\n",
    "            text=df_uf_mapa['uf'],\n",
    "            marker_line_color='white',\n",
    "            colorbar_title=\"RBA M√©dia<br>(R$)\",\n",
    "            hovertemplate='<b>%{text}</b><br>RBA M√©dia: R$ %{z:,.2f}<extra></extra>'\n",
    "        ))\n",
    "        \n",
    "        fig_mapa.update_layout(\n",
    "            title='<b>RBA M√©dia por Estado</b>',\n",
    "            geo=dict(\n",
    "                scope='south america',\n",
    "                showlakes=True,\n",
    "                lakecolor='rgb(255, 255, 255)'\n",
    "            ),\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        fig_mapa.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ESTAT√çSTICAS COMPLEMENTARES\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüìä RESUMO GERAL:\")\n",
    "    print(f\"  ‚Ä¢ Total de Estados: {len(df_uf)}\")\n",
    "    print(f\"  ‚Ä¢ Total de Empresas: {int(df_uf['total_empresas'].sum()):,}\")\n",
    "    print(f\"  ‚Ä¢ Empresas do SN: {int(df_uf['empresas_sn'].sum()):,} ({(df_uf['empresas_sn'].sum() / df_uf['total_empresas'].sum() * 100):.1f}%)\")\n",
    "    print(f\"  ‚Ä¢ Empresas Ativas: {int(total_ativas):,} ({(total_ativas / total_geral * 100):.1f}%)\")\n",
    "    print(f\"  ‚Ä¢ RBA Total: R$ {df_uf['rba_total'].sum():,.2f}\")\n",
    "    print(f\"  ‚Ä¢ Estado Dominante: {df_uf.iloc[0]['uf']} com {int(df_uf.iloc[0]['total_empresas']):,} empresas\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Dados geogr√°ficos n√£o dispon√≠veis ({total_uf} UFs encontradas)\")\n",
    "    print(f\"üí° Esperado: at√© 30 UFs\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ An√°lise geogr√°fica conclu√≠da!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd90ef-4982-4b99-a794-c07326b61f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AN√ÅLISE DE GRUPOS ECON√îMICOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üè¢ AN√ÅLISE DE GRUPOS ECON√îMICOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Estat√≠sticas de grupos\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_stats_grupos AS\n",
    "SELECT \n",
    "    tipo_grupo,\n",
    "    COUNT(DISTINCT num_grupo) AS qtd_grupos,\n",
    "    COUNT(DISTINCT cnpj_raiz) AS qtd_empresas_total,\n",
    "    CAST(AVG(qtd_empresas_grupo) AS DOUBLE) AS media_empresas_por_grupo,\n",
    "    CAST(MAX(qtd_empresas_grupo) AS INT) AS max_empresas_grupo,\n",
    "    COUNT(DISTINCT cpf_socio) AS qtd_socios_unicos\n",
    "FROM gessimples.feitoza_grupos_identificados\n",
    "GROUP BY tipo_grupo\n",
    "ORDER BY qtd_grupos DESC\n",
    "\"\"\")\n",
    "\n",
    "total_grupos_stats = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_stats_grupos\").collect()[0]['cnt']\n",
    "\n",
    "if total_grupos_stats > 0:\n",
    "    df_grupos_stats = spark.sql(\"SELECT * FROM vw_stats_grupos\").toPandas()\n",
    "    \n",
    "    print(f\"\\nüìä ESTAT√çSTICAS DE GRUPOS ECON√îMICOS:\\n\")\n",
    "    for idx, row in df_grupos_stats.iterrows():\n",
    "        print(f\"  {row['tipo_grupo']:20s} ‚Üí \"\n",
    "              f\"{int(row['qtd_grupos']):>5,} grupos | \"\n",
    "              f\"{int(row['qtd_empresas_total']):>6,} empresas | \"\n",
    "              f\"M√©dia: {row['media_empresas_por_grupo']:.1f} empresas/grupo\")\n",
    "    \n",
    "    # Gr√°fico - Distribui√ß√£o de Grupos\n",
    "    fig_grupos = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Quantidade de Grupos por Tipo', 'Total de Empresas por Tipo'),\n",
    "        specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    "    )\n",
    "    \n",
    "    fig_grupos.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_grupos_stats['tipo_grupo'],\n",
    "            y=df_grupos_stats['qtd_grupos'],\n",
    "            marker=dict(color='#1f77b4'),\n",
    "            text=df_grupos_stats['qtd_grupos'],\n",
    "            textposition='outside',\n",
    "            name='Grupos'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig_grupos.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_grupos_stats['tipo_grupo'],\n",
    "            y=df_grupos_stats['qtd_empresas_total'],\n",
    "            marker=dict(color='#ff7f0e'),\n",
    "            text=df_grupos_stats['qtd_empresas_total'],\n",
    "            textposition='outside',\n",
    "            name='Empresas'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig_grupos.update_layout(\n",
    "        title='<b>Distribui√ß√£o de Grupos Econ√¥micos</b>',\n",
    "        height=500,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig_grupos.show()\n",
    "\n",
    "# Top grupos por quantidade de empresas\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_top_grupos AS\n",
    "SELECT \n",
    "    num_grupo,\n",
    "    cpf_socio,\n",
    "    tipo_grupo,\n",
    "    MAX(qtd_empresas_grupo) AS qtd_empresas,\n",
    "    MAX(qtd_empresas_sc) AS qtd_sc,\n",
    "    COUNT(DISTINCT cnpj_raiz) AS empresas_listadas\n",
    "FROM gessimples.feitoza_grupos_identificados\n",
    "GROUP BY num_grupo, cpf_socio, tipo_grupo\n",
    "ORDER BY qtd_empresas DESC\n",
    "LIMIT 20\n",
    "\"\"\")\n",
    "\n",
    "total_top_grupos = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_top_grupos\").collect()[0]['cnt']\n",
    "\n",
    "if total_top_grupos > 0:\n",
    "    df_top_grupos = spark.sql(\"SELECT * FROM vw_top_grupos\").toPandas()\n",
    "    \n",
    "    print(f\"\\nüîù TOP 20 MAIORES GRUPOS ECON√îMICOS:\\n\")\n",
    "    for idx, row in df_top_grupos.iterrows():\n",
    "        cpf_mask = row['cpf_socio'][:3] + '.***.***-' + row['cpf_socio'][-2:] if len(str(row['cpf_socio'])) == 11 else '***'\n",
    "        print(f\"{idx+1:2d}. Grupo {int(row['num_grupo']):>5} | CPF: {cpf_mask} | \"\n",
    "              f\"{int(row['qtd_empresas']):>3} empresas | Tipo: {row['tipo_grupo']}\")\n",
    "    \n",
    "    # Gr√°fico\n",
    "    fig_top_grupos = go.Figure(go.Bar(\n",
    "        y=df_top_grupos['num_grupo'].astype(str),\n",
    "        x=df_top_grupos['qtd_empresas'],\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color=df_top_grupos['qtd_empresas'],\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Qtd<br>Empresas\")\n",
    "        ),\n",
    "        text=df_top_grupos['qtd_empresas'],\n",
    "        textposition='outside',\n",
    "        hovertemplate='<b>Grupo %{y}</b><br>Empresas: %{x}<br>Tipo: %{customdata}<extra></extra>',\n",
    "        customdata=df_top_grupos['tipo_grupo']\n",
    "    ))\n",
    "    \n",
    "    fig_top_grupos.update_layout(\n",
    "        title='<b>Top 20 Maiores Grupos Econ√¥micos</b>',\n",
    "        xaxis_title='Quantidade de Empresas',\n",
    "        yaxis_title='N√∫mero do Grupo',\n",
    "        height=700\n",
    "    )\n",
    "    \n",
    "    fig_top_grupos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e4acce-1715-4b3b-8310-69e908f8fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AN√ÅLISE DE RECEITA BRUTA ACUMULADA (RBA)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí∞ AN√ÅLISE DE RECEITA BRUTA ACUMULADA (RBA)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Estat√≠sticas RBA por status\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_rba_stats AS\n",
    "SELECT \n",
    "    status_rba,\n",
    "    COUNT(DISTINCT cnpj_raiz) AS qtd_empresas,\n",
    "    CAST(COALESCE(SUM(vl_rba_12_meses), 0) AS DOUBLE) AS rba_total,\n",
    "    CAST(COALESCE(AVG(vl_rba_12_meses), 0) AS DOUBLE) AS rba_media,\n",
    "    CAST(COALESCE(MIN(vl_rba_12_meses), 0) AS DOUBLE) AS rba_minima,\n",
    "    CAST(COALESCE(MAX(vl_rba_12_meses), 0) AS DOUBLE) AS rba_maxima\n",
    "FROM gessimples.feitoza_rba_12_meses\n",
    "WHERE vl_rba_12_meses > 0\n",
    "GROUP BY status_rba\n",
    "ORDER BY \n",
    "    CASE status_rba\n",
    "        WHEN 'COMPLETO' THEN 1\n",
    "        WHEN 'PARCIAL' THEN 2\n",
    "        ELSE 3\n",
    "    END\n",
    "\"\"\")\n",
    "\n",
    "total_rba_stats = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_rba_stats\").collect()[0]['cnt']\n",
    "\n",
    "if total_rba_stats > 0:\n",
    "    df_rba_stats = spark.sql(\"SELECT * FROM vw_rba_stats\").toPandas()\n",
    "    \n",
    "    print(f\"\\nüìä ESTAT√çSTICAS DE RBA POR STATUS:\\n\")\n",
    "    for idx, row in df_rba_stats.iterrows():\n",
    "        print(f\"  {row['status_rba']:15s} ‚Üí {int(row['qtd_empresas']):>7,} empresas | \"\n",
    "              f\"Total: R$ {row['rba_total']:>15,.2f} | \"\n",
    "              f\"M√©dia: R$ {row['rba_media']:>12,.2f}\")\n",
    "    \n",
    "    # Gr√°fico - Distribui√ß√£o RBA\n",
    "    fig_rba_dist = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Quantidade de Empresas', 'Volume Total de RBA'),\n",
    "        specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    "    )\n",
    "    \n",
    "    colors = ['#2ca02c', '#ffdd70', '#ff7f0e']\n",
    "    \n",
    "    fig_rba_dist.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_rba_stats['status_rba'],\n",
    "            y=df_rba_stats['qtd_empresas'],\n",
    "            marker=dict(color=colors[:len(df_rba_stats)]),\n",
    "            text=df_rba_stats['qtd_empresas'].apply(lambda x: f'{int(x):,}'),\n",
    "            textposition='outside'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig_rba_dist.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_rba_stats['status_rba'],\n",
    "            y=df_rba_stats['rba_total'] / 1e9,\n",
    "            marker=dict(color=colors[:len(df_rba_stats)]),\n",
    "            text=df_rba_stats['rba_total'].apply(lambda x: f'R$ {x/1e9:.1f}B'),\n",
    "            textposition='outside'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig_rba_dist.update_yaxes(title_text=\"Empresas\", row=1, col=1)\n",
    "    fig_rba_dist.update_yaxes(title_text=\"RBA (Bilh√µes R$)\", row=1, col=2)\n",
    "    \n",
    "    fig_rba_dist.update_layout(\n",
    "        title='<b>Distribui√ß√£o de RBA por Status de Completude</b>',\n",
    "        height=500,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig_rba_dist.show()\n",
    "\n",
    "# Distribui√ß√£o de RBA (Histograma)\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_rba_distribuicao AS\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN vl_rba_12_meses < 1000000 THEN '< R$ 1 MI'\n",
    "        WHEN vl_rba_12_meses < 2000000 THEN 'R$ 1-2 MI'\n",
    "        WHEN vl_rba_12_meses < 3600000 THEN 'R$ 2-3,6 MI'\n",
    "        WHEN vl_rba_12_meses < 4800000 THEN 'R$ 3,6-4,8 MI'\n",
    "        ELSE '> R$ 4,8 MI'\n",
    "    END AS faixa_rba,\n",
    "    COUNT(DISTINCT cnpj_raiz) AS qtd_empresas,\n",
    "    CAST(COALESCE(SUM(vl_rba_12_meses), 0) AS DOUBLE) AS rba_total\n",
    "FROM gessimples.feitoza_rba_12_meses\n",
    "WHERE status_rba = 'COMPLETO'\n",
    "GROUP BY \n",
    "    CASE \n",
    "        WHEN vl_rba_12_meses < 1000000 THEN '< R$ 1 MI'\n",
    "        WHEN vl_rba_12_meses < 2000000 THEN 'R$ 1-2 MI'\n",
    "        WHEN vl_rba_12_meses < 3600000 THEN 'R$ 2-3,6 MI'\n",
    "        WHEN vl_rba_12_meses < 4800000 THEN 'R$ 3,6-4,8 MI'\n",
    "        ELSE '> R$ 4,8 MI'\n",
    "    END\n",
    "ORDER BY \n",
    "    CASE \n",
    "        WHEN faixa_rba = '< R$ 1 MI' THEN 1\n",
    "        WHEN faixa_rba = 'R$ 1-2 MI' THEN 2\n",
    "        WHEN faixa_rba = 'R$ 2-3,6 MI' THEN 3\n",
    "        WHEN faixa_rba = 'R$ 3,6-4,8 MI' THEN 4\n",
    "        ELSE 5\n",
    "    END\n",
    "\"\"\")\n",
    "\n",
    "total_dist = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_rba_distribuicao\").collect()[0]['cnt']\n",
    "\n",
    "if total_dist > 0:\n",
    "    df_rba_dist = spark.sql(\"SELECT * FROM vw_rba_distribuicao\").toPandas()\n",
    "    \n",
    "    print(f\"\\nüìä DISTRIBUI√á√ÉO POR FAIXA DE RBA:\\n\")\n",
    "    for idx, row in df_rba_dist.iterrows():\n",
    "        perc = (row['qtd_empresas'] / df_rba_dist['qtd_empresas'].sum()) * 100\n",
    "        print(f\"  {row['faixa_rba']:15s} ‚Üí {int(row['qtd_empresas']):>7,} empresas ({perc:>5.1f}%)\")\n",
    "    \n",
    "    # Gr√°fico\n",
    "    fig_faixas = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=df_rba_dist['faixa_rba'],\n",
    "            y=df_rba_dist['qtd_empresas'],\n",
    "            marker=dict(\n",
    "                color=df_rba_dist['qtd_empresas'],\n",
    "                colorscale='Blues',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"Empresas\")\n",
    "            ),\n",
    "            text=df_rba_dist['qtd_empresas'].apply(lambda x: f'{int(x):,}'),\n",
    "            textposition='outside'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig_faixas.update_layout(\n",
    "        title='<b>Distribui√ß√£o de Empresas por Faixa de RBA (Dados Completos)</b>',\n",
    "        xaxis_title='Faixa de RBA',\n",
    "        yaxis_title='Quantidade de Empresas',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig_faixas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a3632-9aa9-4ef1-a125-b9a015210873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AN√ÅLISE DE FATO GERADOR - ULTRAPASSAGEM DO LIMITE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚ö†Ô∏è  AN√ÅLISE DE FATO GERADOR - IRREGULARIDADES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Estat√≠sticas de fato gerador\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_fato_gerador_stats AS\n",
    "SELECT \n",
    "    classificacao_risco_fiscal,\n",
    "    gravidade_ultrapassagem,\n",
    "    COUNT(DISTINCT num_grupo) AS qtd_grupos,\n",
    "    COUNT(*) AS qtd_periodos_irregulares,\n",
    "    CAST(COALESCE(SUM(vl_excedente), 0) AS DOUBLE) AS excedente_total,\n",
    "    CAST(COALESCE(AVG(vl_excedente), 0) AS DOUBLE) AS excedente_medio,\n",
    "    CAST(COALESCE(AVG(percentual_excesso), 0) AS DOUBLE) AS perc_excesso_medio\n",
    "FROM gessimples.feitoza_fato_gerador\n",
    "WHERE flag_ultrapassou_limite = 1\n",
    "GROUP BY classificacao_risco_fiscal, gravidade_ultrapassagem\n",
    "ORDER BY \n",
    "    CASE classificacao_risco_fiscal\n",
    "        WHEN 'RISCO_CRITICO' THEN 1\n",
    "        WHEN 'RISCO_ALTO' THEN 2\n",
    "        WHEN 'RISCO_MEDIO' THEN 3\n",
    "        ELSE 4\n",
    "    END,\n",
    "    CASE gravidade_ultrapassagem\n",
    "        WHEN 'GRAVISSIMO' THEN 1\n",
    "        WHEN 'GRAVE' THEN 2\n",
    "        WHEN 'MODERADO' THEN 3\n",
    "        ELSE 4\n",
    "    END\n",
    "\"\"\")\n",
    "\n",
    "total_fg_stats = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_fato_gerador_stats\").collect()[0]['cnt']\n",
    "\n",
    "if total_fg_stats > 0 and total_fg_stats <= 50:\n",
    "    df_fg_stats = spark.sql(\"SELECT * FROM vw_fato_gerador_stats\").toPandas()\n",
    "    \n",
    "    print(f\"\\nüìä IRREGULARIDADES POR RISCO E GRAVIDADE:\\n\")\n",
    "    for idx, row in df_fg_stats.iterrows():\n",
    "        print(f\"  {row['classificacao_risco_fiscal']:15s} | {row['gravidade_ultrapassagem']:12s} ‚Üí \"\n",
    "              f\"{int(row['qtd_grupos']):>5,} grupos | \"\n",
    "              f\"{int(row['qtd_periodos_irregulares']):>6,} per√≠odos | \"\n",
    "              f\"Excedente: R$ {row['excedente_total']:>15,.2f}\")\n",
    "    \n",
    "    # Heatmap - Risco x Gravidade\n",
    "    pivot_fg = df_fg_stats.pivot_table(\n",
    "        index='gravidade_ultrapassagem',\n",
    "        columns='classificacao_risco_fiscal',\n",
    "        values='qtd_grupos',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    fig_heatmap_fg = go.Figure(data=go.Heatmap(\n",
    "        z=pivot_fg.values,\n",
    "        x=pivot_fg.columns,\n",
    "        y=pivot_fg.index,\n",
    "        colorscale='Reds',\n",
    "        text=pivot_fg.values,\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 14},\n",
    "        colorbar=dict(title=\"Qtd<br>Grupos\")\n",
    "    ))\n",
    "    \n",
    "    fig_heatmap_fg.update_layout(\n",
    "        title='<b>Matriz de Risco: Grupos Irregulares por Classifica√ß√£o e Gravidade</b>',\n",
    "        xaxis_title='Classifica√ß√£o de Risco',\n",
    "        yaxis_title='Gravidade da Ultrapassagem',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig_heatmap_fg.show()\n",
    "\n",
    "# Resumo dos grupos irregulares\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_resumo_irregulares AS\n",
    "SELECT \n",
    "    classificacao_risco_maximo,\n",
    "    COUNT(DISTINCT num_grupo) AS qtd_grupos,\n",
    "    CAST(COALESCE(SUM(vl_excedente_maximo), 0) AS DOUBLE) AS excedente_total,\n",
    "    CAST(COALESCE(AVG(vl_rba_maxima_grupo), 0) AS DOUBLE) AS rba_media,\n",
    "    CAST(COALESCE(AVG(qtd_total_periodos_irregulares), 0) AS DOUBLE) AS media_periodos_irreg,\n",
    "    SUM(flag_irregular_atualmente) AS grupos_irregulares_atualmente\n",
    "FROM gessimples.feitoza_resumo_grupos_irregulares\n",
    "GROUP BY classificacao_risco_maximo\n",
    "ORDER BY \n",
    "    CASE classificacao_risco_maximo\n",
    "        WHEN 'RISCO_CRITICO' THEN 1\n",
    "        WHEN 'RISCO_ALTO' THEN 2\n",
    "        WHEN 'RISCO_MEDIO' THEN 3\n",
    "        ELSE 4\n",
    "    END\n",
    "\"\"\")\n",
    "\n",
    "total_resumo = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_resumo_irregulares\").collect()[0]['cnt']\n",
    "\n",
    "if total_resumo > 0:\n",
    "    df_resumo_irreg = spark.sql(\"SELECT * FROM vw_resumo_irregulares\").toPandas()\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  RESUMO DOS GRUPOS IRREGULARES:\\n\")\n",
    "    for idx, row in df_resumo_irreg.iterrows():\n",
    "        print(f\"  {row['classificacao_risco_maximo']:15s} ‚Üí \"\n",
    "              f\"{int(row['qtd_grupos']):>5,} grupos | \"\n",
    "              f\"Excedente: R$ {row['excedente_total']:>15,.2f} | \"\n",
    "              f\"Irregulares agora: {int(row['grupos_irregulares_atualmente']):>4}\")\n",
    "    \n",
    "    # Gr√°ficos\n",
    "    fig_resumo = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Grupos por Risco', 'Excedente Total'),\n",
    "        specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    "    )\n",
    "    \n",
    "    colors_risk = ['#8b0000', '#d62728', '#ff7f0e', '#ffdd70']\n",
    "    \n",
    "    fig_resumo.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_resumo_irreg['classificacao_risco_maximo'],\n",
    "            y=df_resumo_irreg['qtd_grupos'],\n",
    "            marker=dict(color=colors_risk[:len(df_resumo_irreg)]),\n",
    "            text=df_resumo_irreg['qtd_grupos'],\n",
    "            textposition='outside'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig_resumo.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_resumo_irreg['classificacao_risco_maximo'],\n",
    "            y=df_resumo_irreg['excedente_total'] / 1e6,\n",
    "            marker=dict(color=colors_risk[:len(df_resumo_irreg)]),\n",
    "            text=df_resumo_irreg['excedente_total'].apply(lambda x: f'R$ {x/1e6:.1f}M'),\n",
    "            textposition='outside'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig_resumo.update_yaxes(title_text=\"Quantidade de Grupos\", row=1, col=1)\n",
    "    fig_resumo.update_yaxes(title_text=\"Excedente (Milh√µes R$)\", row=1, col=2)\n",
    "    \n",
    "    fig_resumo.update_layout(\n",
    "        title='<b>Resumo de Grupos Irregulares por Risco</b>',\n",
    "        height=500,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig_resumo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f431207-3474-4ba9-9c65-7cca794119a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TOP GRUPOS PARA A√á√ÉO FISCAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ TOP GRUPOS PRIORIT√ÅRIOS PARA FISCALIZA√á√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Top 50 grupos para a√ß√£o fiscal\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_top_fiscalizacao AS\n",
    "SELECT \n",
    "    num_grupo,\n",
    "    cpf_socio,\n",
    "    qtd_empresas_grupo,\n",
    "    lista_cnpj_raiz,\n",
    "    periodo_primeira_ultrapassagem,\n",
    "    periodo_ultima_ultrapassagem,\n",
    "    qtd_total_periodos_irregulares,\n",
    "    CAST(COALESCE(vl_excedente_maximo, 0) AS DOUBLE) AS vl_excedente_maximo,\n",
    "    CAST(COALESCE(percentual_excesso_maximo, 0) AS DOUBLE) AS percentual_excesso_maximo,\n",
    "    classificacao_risco_maximo,\n",
    "    gravidade_maxima,\n",
    "    flag_irregular_atualmente,\n",
    "    CAST(COALESCE(score_priorizacao_fiscal, 0) AS DOUBLE) AS score_priorizacao,\n",
    "    recomendacao_acao\n",
    "FROM gessimples.feitoza_lista_acao_fiscal\n",
    "ORDER BY score_priorizacao_fiscal DESC\n",
    "LIMIT 50\n",
    "\"\"\")\n",
    "\n",
    "total_top_fisc = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_top_fiscalizacao\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de grupos priorit√°rios: {total_top_fisc}\")\n",
    "\n",
    "if total_top_fisc > 0:\n",
    "    df_top_fisc = spark.sql(\"SELECT * FROM vw_top_fiscalizacao\").toPandas()\n",
    "    \n",
    "    print(f\"\\nüîù TOP 20 GRUPOS PARA FISCALIZA√á√ÉO IMEDIATA:\\n\")\n",
    "    for idx, row in df_top_fisc.head(20).iterrows():\n",
    "        cpf_mask = row['cpf_socio'][:3] + '.***.***-' + row['cpf_socio'][-2:] if len(str(row['cpf_socio'])) == 11 else '***'\n",
    "        \n",
    "        print(f\"{idx+1:2d}. Grupo {int(row['num_grupo']):>5} | CPF: {cpf_mask}\")\n",
    "        print(f\"    Score: {row['score_priorizacao']:.1f} | Risco: {row['classificacao_risco_maximo']} | \"\n",
    "              f\"Gravidade: {row['gravidade_maxima']}\")\n",
    "        print(f\"    Empresas: {int(row['qtd_empresas_grupo'])} | \"\n",
    "              f\"Per√≠odos irregulares: {int(row['qtd_total_periodos_irregulares'])}\")\n",
    "        print(f\"    Excedente: R$ {row['vl_excedente_maximo']:,.2f} ({row['percentual_excesso_maximo']:.1f}%)\")\n",
    "        print(f\"    A√ß√£o: {row['recomendacao_acao']}\")\n",
    "        print()\n",
    "    \n",
    "    # Gr√°fico - Score de Prioriza√ß√£o\n",
    "    df_top30 = df_top_fisc.head(30).sort_values('score_priorizacao', ascending=True)\n",
    "    \n",
    "    colors_score = ['#8b0000' if x >= 80 else '#d62728' if x >= 60 else '#ff7f0e' \n",
    "                    for x in df_top30['score_priorizacao']]\n",
    "    \n",
    "    fig_score = go.Figure(go.Bar(\n",
    "        y=df_top30['num_grupo'].astype(str),\n",
    "        x=df_top30['score_priorizacao'],\n",
    "        orientation='h',\n",
    "        marker=dict(color=colors_score),\n",
    "        text=df_top30['score_priorizacao'].apply(lambda x: f'{x:.1f}'),\n",
    "        textposition='outside',\n",
    "        hovertemplate='<b>Grupo %{y}</b><br>Score: %{x:.2f}<br>Empresas: %{customdata[0]}<br>Excedente: R$ %{customdata[1]:,.2f}<extra></extra>',\n",
    "        customdata=df_top30[['qtd_empresas_grupo', 'vl_excedente_maximo']].values\n",
    "    ))\n",
    "    \n",
    "    fig_score.update_layout(\n",
    "        title='<b>Score de Prioriza√ß√£o Fiscal - Top 30 Grupos</b>',\n",
    "        xaxis_title='Score de Prioriza√ß√£o (0-100)',\n",
    "        yaxis_title='N√∫mero do Grupo',\n",
    "        height=900\n",
    "    )\n",
    "    \n",
    "    fig_score.show()\n",
    "    \n",
    "    # Distribui√ß√£o por Recomenda√ß√£o de A√ß√£o\n",
    "    dist_acao = df_top_fisc['recomendacao_acao'].value_counts()\n",
    "    \n",
    "    fig_acao = go.Figure(data=[go.Pie(\n",
    "        labels=dist_acao.index,\n",
    "        values=dist_acao.values,\n",
    "        hole=0.4,\n",
    "        marker=dict(colors=['#8b0000', '#d62728', '#ff7f0e', '#ffdd70']),\n",
    "        textinfo='label+percent+value',\n",
    "        texttemplate='<b>%{label}</b><br>%{value} grupos<br>%{percent:.1%}'\n",
    "    )])\n",
    "    \n",
    "    fig_acao.update_layout(\n",
    "        title='<b>Distribui√ß√£o por Recomenda√ß√£o de A√ß√£o Fiscal</b>',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig_acao.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc09c4-6ebd-4404-b48b-64b9e80b5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PREPARA√á√ÉO DE DADOS PARA MACHINE LEARNING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ü§ñ PREPARA√á√ÉO DE FEATURES PARA MACHINE LEARNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Criar dataset consolidado com features\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_ml_dataset AS\n",
    "SELECT \n",
    "    bc.cnpj_raiz,\n",
    "    bc.uf,\n",
    "    bc.situacao_cadastral_desc,\n",
    "    bc.porte_empresa,\n",
    "    \n",
    "    -- Features de RBA (√∫ltimo per√≠odo)\n",
    "    CAST(COALESCE(rba_ult.vl_rba_12_meses, 0) AS DOUBLE) AS feat_rba_12m,\n",
    "    CAST(COALESCE(rba_ult.vl_receita_bruta_mensal, 0) AS DOUBLE) AS feat_receita_mensal,\n",
    "    CAST(COALESCE(rba_ult.vl_icms_pago, 0) AS DOUBLE) AS feat_icms_pago,\n",
    "    CAST(COALESCE(rba_ult.aliquota_efetiva_12m_perc, 0) AS DOUBLE) AS feat_aliquota_efetiva,\n",
    "    CAST(COALESCE(rba_ult.qtd_meses_com_movimento, 0) AS DOUBLE) AS feat_meses_movimento,\n",
    "    CAST(COALESCE(rba_ult.taxa_atividade, 0) AS DOUBLE) AS feat_taxa_atividade,\n",
    "    \n",
    "    -- Features de grupo\n",
    "    CAST(COALESCE(gi.qtd_empresas_grupo, 1) AS DOUBLE) AS feat_qtd_empresas_grupo,\n",
    "    CASE WHEN gi.tipo_grupo = 'GRUPO_SC_PURO' THEN 1 ELSE 0 END AS feat_grupo_sc_puro,\n",
    "    CASE WHEN gi.flag_socio_ou_titular = 1 THEN 1 ELSE 0 END AS feat_socio_titular,\n",
    "    CASE WHEN gi.flag_socio_responsavel = 1 THEN 1 ELSE 0 END AS feat_socio_responsavel,\n",
    "    \n",
    "    -- Features de irregularidade (TARGET)\n",
    "    CASE WHEN rgi.num_grupo IS NOT NULL THEN 1 ELSE 0 END AS target_irregular,\n",
    "    CASE \n",
    "        WHEN rgi.classificacao_risco_maximo = 'RISCO_CRITICO' THEN 3\n",
    "        WHEN rgi.classificacao_risco_maximo = 'RISCO_ALTO' THEN 2\n",
    "        WHEN rgi.classificacao_risco_maximo = 'RISCO_MEDIO' THEN 1\n",
    "        ELSE 0\n",
    "    END AS target_nivel_risco,\n",
    "    \n",
    "    CAST(COALESCE(rgi.vl_excedente_maximo, 0) AS DOUBLE) AS feat_excedente_maximo,\n",
    "    CAST(COALESCE(rgi.qtd_total_periodos_irregulares, 0) AS DOUBLE) AS feat_periodos_irregulares,\n",
    "    CAST(COALESCE(rgi.percentual_excesso_maximo, 0) AS DOUBLE) AS feat_perc_excesso,\n",
    "    \n",
    "    -- Flags\n",
    "    CASE WHEN bc.situacao_cadastral_desc = 'ATIVA' THEN 1 ELSE 0 END AS flag_ativa,\n",
    "    CASE WHEN psn.cnpj_raiz IS NOT NULL THEN 1 ELSE 0 END AS flag_simples_nacional,\n",
    "    CASE WHEN rba_ult.cnpj_raiz IS NOT NULL THEN 1 ELSE 0 END AS flag_tem_rba\n",
    "\n",
    "FROM gessimples.feitoza_base_cnpj_completo bc\n",
    "\n",
    "LEFT JOIN gessimples.feitoza_base_periodos_sn psn \n",
    "    ON bc.cnpj_raiz = psn.cnpj_raiz\n",
    "\n",
    "LEFT JOIN (\n",
    "    SELECT \n",
    "        cnpj_raiz,\n",
    "        vl_rba_12_meses,\n",
    "        vl_receita_bruta_mensal,\n",
    "        vl_icms_pago,\n",
    "        aliquota_efetiva_12m_perc,\n",
    "        qtd_meses_com_movimento,\n",
    "        taxa_atividade\n",
    "    FROM (\n",
    "        SELECT \n",
    "            *,\n",
    "            ROW_NUMBER() OVER (PARTITION BY cnpj_raiz ORDER BY periodo_apuracao DESC) AS rn\n",
    "        FROM gessimples.feitoza_rba_12_meses\n",
    "        WHERE periodo_apuracao >= 202409\n",
    "          AND status_rba IN ('COMPLETO', 'PARCIAL')\n",
    "    ) ranked\n",
    "    WHERE rn = 1\n",
    ") rba_ult ON bc.cnpj_raiz = rba_ult.cnpj_raiz\n",
    "\n",
    "LEFT JOIN gessimples.feitoza_grupos_identificados gi \n",
    "    ON bc.cnpj_raiz = gi.cnpj_raiz\n",
    "\n",
    "LEFT JOIN gessimples.feitoza_resumo_grupos_irregulares rgi \n",
    "    ON gi.num_grupo = rgi.num_grupo\n",
    "\n",
    "WHERE bc.uf = 'SC'  -- Focar apenas em SC\n",
    "  AND bc.situacao_cadastral_desc = 'ATIVA'  -- Apenas empresas ativas\n",
    "  AND rba_ult.vl_rba_12_meses > 0  -- Com receita\n",
    "\"\"\")\n",
    "\n",
    "# Verificar tamanho\n",
    "total_ml = spark.sql(\"SELECT COUNT(*) as cnt FROM vw_ml_dataset\").collect()[0]['cnt']\n",
    "print(f\"\\nüìä Total de registros para ML: {total_ml:,}\")\n",
    "\n",
    "if total_ml > 0:\n",
    "    # Verificar se √© muito grande\n",
    "    if total_ml > 200000:\n",
    "        print(f\"‚ö†Ô∏è  Dataset muito grande ({total_ml:,} registros)\")\n",
    "        print(f\"üîÑ Limitando para 200.000 registros aleat√≥rios...\")\n",
    "        \n",
    "        # Sample aleat√≥rio\n",
    "        df_ml_spark = (spark.sql(\"SELECT * FROM vw_ml_dataset\")\n",
    "                       .sample(fraction=200000/total_ml, seed=42))\n",
    "    else:\n",
    "        df_ml_spark = spark.sql(\"SELECT * FROM vw_ml_dataset\")\n",
    "    \n",
    "    # Cachear\n",
    "    df_ml_spark.cache()\n",
    "    \n",
    "    # Converter para Pandas\n",
    "    print(f\"üîÑ Convertendo para Pandas...\")\n",
    "    df_ml = df_ml_spark.toPandas()\n",
    "    \n",
    "    print(f\"‚úÖ Dataset carregado: {len(df_ml):,} registros √ó {len(df_ml.columns)} colunas\")\n",
    "    \n",
    "    # An√°lise da distribui√ß√£o do target\n",
    "    print(f\"\\nüéØ DISTRIBUI√á√ÉO DO TARGET:\")\n",
    "    dist_target = df_ml['target_irregular'].value_counts()\n",
    "    total_records = len(df_ml)\n",
    "    print(f\"  ‚Ä¢ N√£o Irregulares (0): {dist_target.get(0, 0):,} ({dist_target.get(0, 0)/total_records*100:.1f}%)\")\n",
    "    print(f\"  ‚Ä¢ Irregulares (1): {dist_target.get(1, 0):,} ({dist_target.get(1, 0)/total_records*100:.1f}%)\")\n",
    "    \n",
    "    # Estat√≠sticas descritivas\n",
    "    print(f\"\\nüìä ESTAT√çSTICAS DAS FEATURES PRINCIPAIS:\\n\")\n",
    "    features_principais = ['feat_rba_12m', 'feat_receita_mensal', 'feat_qtd_empresas_grupo', \n",
    "                          'feat_excedente_maximo', 'feat_periodos_irregulares']\n",
    "    \n",
    "    stats_df = df_ml[features_principais].describe()\n",
    "    print(stats_df.to_string())\n",
    "    \n",
    "    # Verificar valores faltantes\n",
    "    missing_summary = df_ml.isnull().sum()\n",
    "    if missing_summary.sum() > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  VALORES FALTANTES ENCONTRADOS:\")\n",
    "        for col, missing_count in missing_summary[missing_summary > 0].items():\n",
    "            print(f\"   ‚Ä¢ {col}: {missing_count:,} ({missing_count/len(df_ml)*100:.2f}%)\")\n",
    "        \n",
    "        # Preencher NaN com 0\n",
    "        df_ml = df_ml.fillna(0)\n",
    "        print(f\"\\n‚úÖ Valores faltantes preenchidos com 0\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Nenhum valor faltante encontrado!\")\n",
    "    \n",
    "    # Gr√°fico - Distribui√ß√£o do Target\n",
    "    fig_target = go.Figure(data=[go.Pie(\n",
    "        labels=['Regular', 'Irregular'],\n",
    "        values=[dist_target.get(0, 0), dist_target.get(1, 0)],\n",
    "        hole=0.4,\n",
    "        marker=dict(colors=['#2ca02c', '#d62728']),\n",
    "        textinfo='label+percent+value',\n",
    "        texttemplate='<b>%{label}</b><br>%{value:,}<br>%{percent:.1%}'\n",
    "    )])\n",
    "    \n",
    "    fig_target.update_layout(\n",
    "        title='<b>Distribui√ß√£o do Target - Grupos Irregulares</b>',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig_target.show()\n",
    "    \n",
    "    print(f\"\\nüíæ DATASET PREPARADO:\")\n",
    "    print(f\"   ‚Ä¢ Vari√°vel: df_ml\")\n",
    "    print(f\"   ‚Ä¢ Shape: {df_ml.shape}\")\n",
    "    print(f\"   ‚Ä¢ Mem√≥ria: {df_ml.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado dispon√≠vel para ML\")\n",
    "    df_ml = None\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ PREPARA√á√ÉO PARA ML CONCLU√çDA!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dde7ff-524f-4651-bc07-a72f262d5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AN√ÅLISE EXPLORAT√ìRIA DAS FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä AN√ÅLISE EXPLORAT√ìRIA DE FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if df_ml is not None and len(df_ml) > 0:\n",
    "    # Features num√©ricas\n",
    "    features_numericas = [col for col in df_ml.columns if col.startswith('feat_')]\n",
    "    \n",
    "    print(f\"\\nüìã Total de features num√©ricas: {len(features_numericas)}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MATRIZ DE CORRELA√á√ÉO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüîó Calculando matriz de correla√ß√£o...\")\n",
    "    corr_matrix = df_ml[features_numericas + ['target_irregular']].corr()\n",
    "    \n",
    "    # Heatmap de correla√ß√£o\n",
    "    fig_corr = go.Figure(data=go.Heatmap(\n",
    "        z=corr_matrix.values,\n",
    "        x=corr_matrix.columns,\n",
    "        y=corr_matrix.columns,\n",
    "        colorscale='RdBu',\n",
    "        zmid=0,\n",
    "        text=np.round(corr_matrix.values, 2),\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 7},\n",
    "        hovertemplate='%{y} vs %{x}<br>Correla√ß√£o: %{z:.3f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig_corr.update_layout(\n",
    "        title='<b>Matriz de Correla√ß√£o entre Features</b>',\n",
    "        height=800,\n",
    "        width=900,\n",
    "        xaxis=dict(tickangle=-45, tickfont=dict(size=8)),\n",
    "        yaxis=dict(tickfont=dict(size=8))\n",
    "    )\n",
    "    \n",
    "    fig_corr.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TOP CORRELA√á√ïES COM TARGET\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüéØ TOP 10 FEATURES MAIS CORRELACIONADAS COM TARGET:\\n\")\n",
    "    target_corr = corr_matrix['target_irregular'].drop('target_irregular').abs().sort_values(ascending=False)\n",
    "    \n",
    "    for idx, (feat, corr_val) in enumerate(target_corr.head(10).items(), 1):\n",
    "        corr_original = corr_matrix['target_irregular'][feat]\n",
    "        print(f\"  {idx:2d}. {feat:35s} ‚Üí {corr_original:+.4f}\")\n",
    "    \n",
    "    # ‚úÖ CORRE√á√ÉO: Usar list comprehension ao inv√©s de .apply()\n",
    "    top_corr = target_corr.head(10)\n",
    "    \n",
    "    fig_top_corr = go.Figure(go.Bar(\n",
    "        y=top_corr.index,\n",
    "        x=top_corr.values,\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color=top_corr.values,\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Correla√ß√£o<br>Absoluta\")\n",
    "        ),\n",
    "        text=[f'{x:.3f}' for x in top_corr.values],  # ‚úÖ List comprehension\n",
    "        textposition='outside'\n",
    "    ))\n",
    "    \n",
    "    fig_top_corr.update_layout(\n",
    "        title='<b>Top 10 Features com Maior Correla√ß√£o com Target (Absoluta)</b>',\n",
    "        xaxis_title='Correla√ß√£o Absoluta',\n",
    "        yaxis_title='Feature',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig_top_corr.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DISTRIBUI√á√ÉO DAS FEATURES POR CLASSE\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüìä Gerando distribui√ß√µes das features por classe...\")\n",
    "    \n",
    "    features_plot = ['feat_rba_12m', 'feat_receita_mensal', 'feat_qtd_empresas_grupo',\n",
    "                     'feat_excedente_maximo', 'feat_periodos_irregulares', 'feat_taxa_atividade']\n",
    "    \n",
    "    fig_dist = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=[f.replace('feat_', '').replace('_', ' ').title() for f in features_plot],\n",
    "        vertical_spacing=0.12,\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    positions = [(1,1), (1,2), (2,1), (2,2), (3,1), (3,2)]\n",
    "    colors_dist = ['#2ca02c', '#d62728']\n",
    "    \n",
    "    for idx, feat in enumerate(features_plot):\n",
    "        row, col = positions[idx]\n",
    "        \n",
    "        # Histograma para cada classe\n",
    "        for class_val, color in zip([0, 1], colors_dist):\n",
    "            data_class = df_ml[df_ml['target_irregular'] == class_val][feat]\n",
    "            \n",
    "            fig_dist.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=data_class,\n",
    "                    name=f\"Classe {class_val}\",\n",
    "                    opacity=0.6,\n",
    "                    marker=dict(color=color),\n",
    "                    showlegend=(idx == 0),\n",
    "                    nbinsx=30\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "    \n",
    "    fig_dist.update_layout(\n",
    "        title='<b>Distribui√ß√£o das Features por Classe (0=Regular, 1=Irregular)</b>',\n",
    "        height=900,\n",
    "        barmode='overlay',\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig_dist.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # BOXPLOTS - Features vs Target\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüì¶ Gerando boxplots...\")\n",
    "    \n",
    "    fig_box = make_subplots(\n",
    "        rows=2, cols=3,\n",
    "        subplot_titles=[f.replace('feat_', '').replace('_', ' ').title() for f in features_plot],\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    positions_box = [(1,1), (1,2), (1,3), (2,1), (2,2), (2,3)]\n",
    "    \n",
    "    for idx, feat in enumerate(features_plot):\n",
    "        row, col = positions_box[idx]\n",
    "        \n",
    "        for class_val, color in zip([0, 1], colors_dist):\n",
    "            data_class = df_ml[df_ml['target_irregular'] == class_val][feat]\n",
    "            \n",
    "            fig_box.add_trace(\n",
    "                go.Box(\n",
    "                    y=data_class,\n",
    "                    name=f\"Classe {class_val}\",\n",
    "                    marker=dict(color=color),\n",
    "                    showlegend=(idx == 0)\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "    \n",
    "    fig_box.update_layout(\n",
    "        title='<b>Boxplots: Features por Classe</b>',\n",
    "        height=700,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig_box.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SCATTER PLOT - RBA vs Excedente\n",
    "    # ========================================================================\n",
    "    \n",
    "    if df_ml['feat_excedente_maximo'].sum() > 0:  # Se houver excedente\n",
    "        print(f\"\\nüìà Gerando scatter plot: RBA vs Excedente...\")\n",
    "        \n",
    "        # Filtrar apenas quem tem excedente\n",
    "        df_scatter = df_ml[df_ml['feat_excedente_maximo'] > 0].copy()\n",
    "        \n",
    "        if len(df_scatter) > 0:\n",
    "            fig_scatter = go.Figure()\n",
    "            \n",
    "            for class_val, color, name in zip([0, 1], ['#2ca02c', '#d62728'], ['Regular', 'Irregular']):\n",
    "                data_class = df_scatter[df_scatter['target_irregular'] == class_val]\n",
    "                \n",
    "                fig_scatter.add_trace(go.Scatter(\n",
    "                    x=data_class['feat_rba_12m'] / 1e6,\n",
    "                    y=data_class['feat_excedente_maximo'] / 1e6,\n",
    "                    mode='markers',\n",
    "                    name=name,\n",
    "                    marker=dict(\n",
    "                        size=8,\n",
    "                        color=color,\n",
    "                        opacity=0.6\n",
    "                    ),\n",
    "                    hovertemplate='<b>%{fullData.name}</b><br>RBA: R$ %{x:.2f}M<br>Excedente: R$ %{y:.2f}M<extra></extra>'\n",
    "                ))\n",
    "            \n",
    "            fig_scatter.update_layout(\n",
    "                title='<b>Rela√ß√£o: RBA 12 Meses vs Excedente M√°ximo</b>',\n",
    "                xaxis_title='RBA 12 Meses (Milh√µes R$)',\n",
    "                yaxis_title='Excedente M√°ximo (Milh√µes R$)',\n",
    "                height=500,\n",
    "                showlegend=True\n",
    "            )\n",
    "            \n",
    "            fig_scatter.show()\n",
    "    \n",
    "    print(f\"\\n‚úÖ An√°lise explorat√≥ria conclu√≠da!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Dataset n√£o dispon√≠vel\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d351b6a-9b3f-4d05-b7dd-d6892694c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MACHINE LEARNING: RANDOM FOREST CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üå≤ RANDOM FOREST - CLASSIFICA√á√ÉO DE GRUPOS IRREGULARES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if df_ml is not None and len(df_ml) > 0:\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                                  roc_auc_score, roc_curve, accuracy_score, \n",
    "                                  precision_score, recall_score, f1_score)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Selecionar features independentes (sem leakage)\n",
    "    features_rf = [\n",
    "        'feat_rba_12m',\n",
    "        'feat_receita_mensal',\n",
    "        'feat_icms_pago',\n",
    "        'feat_aliquota_efetiva',\n",
    "        'feat_meses_movimento',\n",
    "        'feat_taxa_atividade',\n",
    "        'feat_qtd_empresas_grupo',\n",
    "        'feat_grupo_sc_puro',\n",
    "        'feat_socio_titular',\n",
    "        'feat_socio_responsavel',\n",
    "        'flag_simples_nacional'\n",
    "    ]\n",
    "    \n",
    "    X = df_ml[features_rf].fillna(0)\n",
    "    y = df_ml['target_irregular']\n",
    "    \n",
    "    print(f\"\\nüìä Dataset para treinamento:\")\n",
    "    print(f\"  ‚Ä¢ Features: {len(features_rf)}\")\n",
    "    print(f\"  ‚Ä¢ Amostras: {len(X):,}\")\n",
    "    print(f\"  ‚Ä¢ Distribui√ß√£o: Regular={y.value_counts().get(0, 0):,}, Irregular={y.value_counts().get(1, 0):,}\")\n",
    "    \n",
    "    # Split treino/teste\n",
    "    print(f\"\\n‚úÇÔ∏è  Dividindo em treino (70%) e teste (30%)...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"  ‚Ä¢ Treino: {len(X_train):,} amostras\")\n",
    "    print(f\"  ‚Ä¢ Teste: {len(X_test):,} amostras\")\n",
    "    \n",
    "    # Normaliza√ß√£o\n",
    "    print(f\"\\n‚öôÔ∏è  Normalizando features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Treinar modelo\n",
    "    print(f\"\\nüå≤ Treinando Random Forest...\")\n",
    "    \n",
    "    # Calcular peso de classes\n",
    "    class_weights = len(y_train) / (2 * np.bincount(y_train))\n",
    "    weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "    \n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        class_weight=weight_dict,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    print(f\"‚úÖ Modelo treinado!\")\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_pred = rf_model.predict(X_test_scaled)\n",
    "    y_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    print(f\"\\nüìä M√âTRICAS DE DESEMPENHO:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Regular', 'Irregular']))\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nüéØ RESUMO DAS M√âTRICAS:\")\n",
    "    print(f\"  ‚Ä¢ Acur√°cia: {accuracy:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Precis√£o: {precision:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Recall: {recall:.4f}\")\n",
    "    print(f\"  ‚Ä¢ F1-Score: {f1:.4f}\")\n",
    "    print(f\"  ‚Ä¢ AUC-ROC: {auc_score:.4f}\")\n",
    "    \n",
    "    # Valida√ß√£o cruzada\n",
    "    print(f\"\\nüîÑ Valida√ß√£o cruzada (5-fold)...\")\n",
    "    cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    print(f\"   AUC m√©dio CV: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICOS\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Matriz de confus√£o\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    fig_cm = go.Figure(data=go.Heatmap(\n",
    "        z=cm,\n",
    "        x=['Regular', 'Irregular'],\n",
    "        y=['Regular', 'Irregular'],\n",
    "        text=cm,\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 20},\n",
    "        colorscale='Blues'\n",
    "    ))\n",
    "    \n",
    "    fig_cm.update_layout(\n",
    "        title='<b>Matriz de Confus√£o - Random Forest</b>',\n",
    "        xaxis_title='Predi√ß√£o',\n",
    "        yaxis_title='Real',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig_cm.show()\n",
    "    \n",
    "    # Curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    \n",
    "    fig_roc = go.Figure()\n",
    "    \n",
    "    fig_roc.add_trace(go.Scatter(\n",
    "        x=fpr, y=tpr,\n",
    "        mode='lines',\n",
    "        name=f'Random Forest (AUC = {auc_score:.3f})',\n",
    "        line=dict(color='#1f77b4', width=3)\n",
    "    ))\n",
    "    \n",
    "    fig_roc.add_trace(go.Scatter(\n",
    "        x=[0, 1], y=[0, 1],\n",
    "        mode='lines',\n",
    "        name='Baseline (Random)',\n",
    "        line=dict(color='red', width=2, dash='dash')\n",
    "    ))\n",
    "    \n",
    "    fig_roc.update_layout(\n",
    "        title='<b>Curva ROC - Random Forest</b>',\n",
    "        xaxis_title='Taxa de Falsos Positivos (FPR)',\n",
    "        yaxis_title='Taxa de Verdadeiros Positivos (TPR)',\n",
    "        height=500,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig_roc.show()\n",
    "    \n",
    "    # Import√¢ncia das features\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features_rf,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüìä IMPORT√ÇNCIA DAS FEATURES:\\n\")\n",
    "    for idx, row in feature_importance.iterrows():\n",
    "        print(f\"  {row['feature']:35s} ‚Üí {row['importance']:.6f}\")\n",
    "    \n",
    "    fig_importance = go.Figure(go.Bar(\n",
    "        y=feature_importance['feature'],\n",
    "        x=feature_importance['importance'],\n",
    "        orientation='h',\n",
    "        marker=dict(color=feature_importance['importance'], colorscale='Viridis'),\n",
    "        text=feature_importance['importance'].apply(lambda x: f'{x:.4f}'),\n",
    "        textposition='outside'\n",
    "    ))\n",
    "    \n",
    "    fig_importance.update_layout(\n",
    "        title='<b>Import√¢ncia das Features - Random Forest</b>',\n",
    "        xaxis_title='Import√¢ncia',\n",
    "        yaxis_title='Feature',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig_importance.show()\n",
    "    \n",
    "    # Salvar modelo e probabilidades\n",
    "    df_ml['rf_probability'] = np.nan\n",
    "    df_ml.loc[X_test.index, 'rf_probability'] = y_pred_proba\n",
    "    \n",
    "    print(f\"\\nüíæ Probabilidades salvas em df_ml['rf_probability']\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Dataset n√£o dispon√≠vel\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ RANDOM FOREST CONCLU√çDO!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5af033-b8d1-456f-b5e8-01ddec22ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MACHINE LEARNING: XGBOOST CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚ö° XGBOOST - CLASSIFICA√á√ÉO DE GRUPOS IRREGULARES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if df_ml is not None and len(df_ml) > 0:\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "    \n",
    "    # Usar as mesmas features do Random Forest\n",
    "    features_xgb = [\n",
    "        'feat_rba_12m',\n",
    "        'feat_receita_mensal',\n",
    "        'feat_icms_pago',\n",
    "        'feat_aliquota_efetiva',\n",
    "        'feat_meses_movimento',\n",
    "        'feat_taxa_atividade',\n",
    "        'feat_qtd_empresas_grupo',\n",
    "        'feat_grupo_sc_puro',\n",
    "        'feat_socio_titular',\n",
    "        'feat_socio_responsavel',\n",
    "        'flag_simples_nacional'\n",
    "    ]\n",
    "    \n",
    "    X = df_ml[features_xgb].fillna(0)\n",
    "    y = df_ml['target_irregular']\n",
    "    \n",
    "    # Usar o mesmo split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Normaliza√ß√£o\n",
    "    scaler_xgb = StandardScaler()\n",
    "    X_train_scaled = scaler_xgb.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_xgb.transform(X_test)\n",
    "    \n",
    "    print(f\"\\n‚öôÔ∏è  Configurando XGBoost...\")\n",
    "    \n",
    "    # Calcular scale_pos_weight para desbalanceamento\n",
    "    scale_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    print(f\"  ‚Ä¢ Scale Pos Weight: {scale_weight:.2f}\")\n",
    "    \n",
    "    # Treinar modelo\n",
    "    print(f\"\\n‚ö° Treinando XGBoost...\")\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=scale_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(X_train_scaled, y_train)\n",
    "    print(f\"‚úÖ Modelo treinado!\")\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "    y_pred_proba_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    print(f\"\\nüìä M√âTRICAS DE DESEMPENHO - XGBOOST:\\n\")\n",
    "    print(classification_report(y_test, y_pred_xgb, target_names=['Regular', 'Irregular']))\n",
    "    \n",
    "    auc_xgb = roc_auc_score(y_test, y_pred_proba_xgb)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "    recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "    f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "    \n",
    "    print(f\"\\nüéØ RESUMO DAS M√âTRICAS:\")\n",
    "    print(f\"  ‚Ä¢ Acur√°cia: {accuracy_xgb:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Precis√£o: {precision_xgb:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Recall: {recall_xgb:.4f}\")\n",
    "    print(f\"  ‚Ä¢ F1-Score: {f1_xgb:.4f}\")\n",
    "    print(f\"  ‚Ä¢ AUC-ROC: {auc_xgb:.4f}\")\n",
    "    \n",
    "    # Valida√ß√£o cruzada\n",
    "    print(f\"\\nüîÑ Valida√ß√£o cruzada (5-fold)...\")\n",
    "    cv_scores_xgb = cross_val_score(xgb_model, X_train_scaled, y_train, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    print(f\"   AUC m√©dio CV: {cv_scores_xgb.mean():.4f} (¬±{cv_scores_xgb.std():.4f})\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # COMPARA√á√ÉO: RF vs XGBoost\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüìä COMPARA√á√ÉO DE MODELOS:\")\n",
    "    print(f\"  ‚Ä¢ Random Forest AUC: {auc_score:.4f}\")\n",
    "    print(f\"  ‚Ä¢ XGBoost AUC: {auc_xgb:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Diferen√ßa: {abs(auc_xgb - auc_score):.4f}\")\n",
    "    \n",
    "    if auc_xgb > auc_score:\n",
    "        print(f\"  ‚úÖ XGBoost √© {((auc_xgb/auc_score - 1)*100):.2f}% melhor\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ Random Forest √© {((auc_score/auc_xgb - 1)*100):.2f}% melhor\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # GR√ÅFICOS\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Curvas ROC comparadas\n",
    "    fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_pred_proba_xgb)\n",
    "    \n",
    "    fig_compare = go.Figure()\n",
    "    \n",
    "    fig_compare.add_trace(go.Scatter(\n",
    "        x=fpr, y=tpr,\n",
    "        mode='lines',\n",
    "        name=f'Random Forest (AUC = {auc_score:.3f})',\n",
    "        line=dict(color='#1f77b4', width=3)\n",
    "    ))\n",
    "    \n",
    "    fig_compare.add_trace(go.Scatter(\n",
    "        x=fpr_xgb, y=tpr_xgb,\n",
    "        mode='lines',\n",
    "        name=f'XGBoost (AUC = {auc_xgb:.3f})',\n",
    "        line=dict(color='#ff7f0e', width=3)\n",
    "    ))\n",
    "    \n",
    "    fig_compare.add_trace(go.Scatter(\n",
    "        x=[0, 1], y=[0, 1],\n",
    "        mode='lines',\n",
    "        name='Baseline (Random)',\n",
    "        line=dict(color='red', width=2, dash='dash')\n",
    "    ))\n",
    "    \n",
    "    fig_compare.update_layout(\n",
    "        title='<b>Compara√ß√£o: Random Forest vs XGBoost - Curvas ROC</b>',\n",
    "        xaxis_title='Taxa de Falsos Positivos (FPR)',\n",
    "        yaxis_title='Taxa de Verdadeiros Positivos (TPR)',\n",
    "        height=500,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig_compare.show()\n",
    "    \n",
    "    # Matriz de confus√£o XGBoost\n",
    "    cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "    \n",
    "    fig_cm_xgb = go.Figure(data=go.Heatmap(\n",
    "        z=cm_xgb,\n",
    "        x=['Regular', 'Irregular'],\n",
    "        y=['Regular', 'Irregular'],\n",
    "        text=cm_xgb,\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 20},\n",
    "        colorscale='Oranges'\n",
    "    ))\n",
    "    \n",
    "    fig_cm_xgb.update_layout(\n",
    "        title='<b>Matriz de Confus√£o - XGBoost</b>',\n",
    "        xaxis_title='Predi√ß√£o',\n",
    "        yaxis_title='Real',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig_cm_xgb.show()\n",
    "    \n",
    "    # Import√¢ncia das features - XGBoost\n",
    "    feature_importance_xgb = pd.DataFrame({\n",
    "        'feature': features_xgb,\n",
    "        'importance': xgb_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüìä IMPORT√ÇNCIA DAS FEATURES - XGBOOST:\\n\")\n",
    "    for idx, row in feature_importance_xgb.iterrows():\n",
    "        print(f\"  {row['feature']:35s} ‚Üí {row['importance']:.6f}\")\n",
    "    \n",
    "    fig_importance_xgb = go.Figure(go.Bar(\n",
    "        y=feature_importance_xgb['feature'],\n",
    "        x=feature_importance_xgb['importance'],\n",
    "        orientation='h',\n",
    "        marker=dict(color=feature_importance_xgb['importance'], colorscale='Plasma'),\n",
    "        text=[f'{x:.4f}' for x in feature_importance_xgb['importance'].values],\n",
    "        textposition='outside'\n",
    "    ))\n",
    "    \n",
    "    fig_importance_xgb.update_layout(\n",
    "        title='<b>Import√¢ncia das Features - XGBoost</b>',\n",
    "        xaxis_title='Import√¢ncia',\n",
    "        yaxis_title='Feature',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig_importance_xgb.show()\n",
    "    \n",
    "    # Compara√ß√£o de import√¢ncia\n",
    "    fig_comp_importance = go.Figure()\n",
    "    \n",
    "    fig_comp_importance.add_trace(go.Bar(\n",
    "        name='Random Forest',\n",
    "        y=feature_importance['feature'],\n",
    "        x=feature_importance['importance'],\n",
    "        orientation='h',\n",
    "        marker=dict(color='#1f77b4')\n",
    "    ))\n",
    "    \n",
    "    fig_comp_importance.add_trace(go.Bar(\n",
    "        name='XGBoost',\n",
    "        y=feature_importance_xgb['feature'],\n",
    "        x=feature_importance_xgb['importance'],\n",
    "        orientation='h',\n",
    "        marker=dict(color='#ff7f0e')\n",
    "    ))\n",
    "    \n",
    "    fig_comp_importance.update_layout(\n",
    "        title='<b>Compara√ß√£o: Import√¢ncia das Features (RF vs XGBoost)</b>',\n",
    "        xaxis_title='Import√¢ncia',\n",
    "        yaxis_title='Feature',\n",
    "        height=600,\n",
    "        barmode='group'\n",
    "    )\n",
    "    \n",
    "    fig_comp_importance.show()\n",
    "    \n",
    "    # Salvar probabilidades\n",
    "    df_ml['xgb_probability'] = np.nan\n",
    "    df_ml.loc[X_test.index, 'xgb_probability'] = y_pred_proba_xgb\n",
    "    \n",
    "    # Ensemble (m√©dia das probabilidades)\n",
    "    df_ml['ensemble_probability'] = (df_ml['rf_probability'] + df_ml['xgb_probability']) / 2\n",
    "    \n",
    "    print(f\"\\nüíæ Probabilidades XGBoost e Ensemble salvas em df_ml\")\n",
    "    \n",
    "    # An√°lise do Ensemble\n",
    "    mask_ensemble = df_ml['ensemble_probability'].notna()\n",
    "    y_pred_ensemble = (df_ml.loc[mask_ensemble, 'ensemble_probability'] >= 0.5).astype(int)\n",
    "    y_test_ensemble = df_ml.loc[mask_ensemble, 'target_irregular']\n",
    "    \n",
    "    if len(y_test_ensemble) > 0:\n",
    "        auc_ensemble = roc_auc_score(y_test_ensemble, df_ml.loc[mask_ensemble, 'ensemble_probability'])\n",
    "        \n",
    "        print(f\"\\nüéØ COMPARA√á√ÉO FINAL DOS MODELOS:\")\n",
    "        print(f\"  ‚Ä¢ Random Forest AUC: {auc_score:.4f}\")\n",
    "        print(f\"  ‚Ä¢ XGBoost AUC: {auc_xgb:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Ensemble (M√©dia) AUC: {auc_ensemble:.4f}\")\n",
    "        \n",
    "        # Melhor modelo\n",
    "        import builtins\n",
    "        modelos_comparacao = [\n",
    "            ('Random Forest', auc_score), \n",
    "            ('XGBoost', auc_xgb), \n",
    "            ('Ensemble', auc_ensemble)\n",
    "        ]\n",
    "        best_model = builtins.max(modelos_comparacao, key=lambda x: x[1])\n",
    "        print(f\"\\nüèÜ MELHOR MODELO: {best_model[0]} (AUC = {best_model[1]:.4f})\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Dataset n√£o dispon√≠vel para XGBoost\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ XGBOOST CONCLU√çDO!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e1634-86d8-4fab-8354-0b8dac09d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# APRENDIZADO N√ÉO SUPERVISIONADO: K-MEANS CLUSTERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üé≤ K-MEANS CLUSTERING - SEGMENTA√á√ÉO DE EMPRESAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if df_ml is not None and len(df_ml) > 0:\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Selecionar features para clustering\n",
    "    features_cluster = [\n",
    "        'feat_rba_12m',\n",
    "        'feat_receita_mensal',\n",
    "        'feat_icms_pago',\n",
    "        'feat_aliquota_efetiva',\n",
    "        'feat_meses_movimento',\n",
    "        'feat_taxa_atividade',\n",
    "        'feat_qtd_empresas_grupo'\n",
    "    ]\n",
    "    \n",
    "    df_cluster = df_ml[features_cluster].copy()\n",
    "    df_cluster = df_cluster.fillna(0)\n",
    "    \n",
    "    print(f\"\\nüìä Features selecionadas para clustering:\")\n",
    "    for feat in features_cluster:\n",
    "        print(f\"  ‚Ä¢ {feat}\")\n",
    "    \n",
    "    # Normaliza√ß√£o\n",
    "    print(f\"\\n‚öôÔ∏è  Normalizando features...\")\n",
    "    scaler_cluster = StandardScaler()\n",
    "    X_scaled = scaler_cluster.fit_transform(df_cluster)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # M√âTODO DO COTOVELO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüìà Calculando m√©todo do cotovelo...\")\n",
    "    inertias = []\n",
    "    silhouette_scores = []\n",
    "    K_range = range(2, 11)\n",
    "    \n",
    "    from sklearn.metrics import silhouette_score\n",
    "    \n",
    "    for k in K_range:\n",
    "        kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans_temp.fit(X_scaled)\n",
    "        inertias.append(kmeans_temp.inertia_)\n",
    "        silhouette_scores.append(silhouette_score(X_scaled, kmeans_temp.labels_))\n",
    "        print(f\"  K={k}: Inertia={kmeans_temp.inertia_:.0f}, Silhouette={silhouette_scores[-1]:.3f}\")\n",
    "    \n",
    "    # Gr√°fico do cotovelo\n",
    "    fig_elbow = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('M√©todo do Cotovelo', 'Silhouette Score'),\n",
    "        specs=[[{'type': 'scatter'}, {'type': 'scatter'}]]\n",
    "    )\n",
    "    \n",
    "    fig_elbow.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(K_range),\n",
    "            y=inertias,\n",
    "            mode='lines+markers',\n",
    "            marker=dict(size=10, color='#1f77b4'),\n",
    "            line=dict(width=2),\n",
    "            name='In√©rcia'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig_elbow.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(K_range),\n",
    "            y=silhouette_scores,\n",
    "            mode='lines+markers',\n",
    "            marker=dict(size=10, color='#ff7f0e'),\n",
    "            line=dict(width=2),\n",
    "            name='Silhouette'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig_elbow.update_xaxes(title_text=\"N√∫mero de Clusters (K)\", row=1, col=1)\n",
    "    fig_elbow.update_xaxes(title_text=\"N√∫mero de Clusters (K)\", row=1, col=2)\n",
    "    fig_elbow.update_yaxes(title_text=\"In√©rcia\", row=1, col=1)\n",
    "    fig_elbow.update_yaxes(title_text=\"Silhouette Score\", row=1, col=2)\n",
    "    \n",
    "    fig_elbow.update_layout(\n",
    "        title='<b>Determina√ß√£o do K Ideal</b>',\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig_elbow.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # APLICAR K-MEANS\n",
    "    # ========================================================================\n",
    "    \n",
    "    k_optimal = 4\n",
    "    print(f\"\\nüéØ Aplicando K-Means com K={k_optimal}...\")\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k_optimal, random_state=42, n_init=10)\n",
    "    df_ml['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # AN√ÅLISE DOS CLUSTERS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüìä AN√ÅLISE DOS CLUSTERS:\\n\")\n",
    "    for cluster_id in range(k_optimal):\n",
    "        cluster_data = df_ml[df_ml['cluster'] == cluster_id]\n",
    "        print(f\"Cluster {cluster_id}:\")\n",
    "        print(f\"  ‚Ä¢ Tamanho: {len(cluster_data):,} empresas ({len(cluster_data)/len(df_ml)*100:.1f}%)\")\n",
    "        print(f\"  ‚Ä¢ RBA M√©dia: R$ {cluster_data['feat_rba_12m'].mean():,.2f}\")\n",
    "        print(f\"  ‚Ä¢ Receita Mensal M√©dia: R$ {cluster_data['feat_receita_mensal'].mean():,.2f}\")\n",
    "        print(f\"  ‚Ä¢ Empresas/Grupo M√©dio: {cluster_data['feat_qtd_empresas_grupo'].mean():.1f}\")\n",
    "        print(f\"  ‚Ä¢ % Irregulares: {(cluster_data['target_irregular'].sum()/len(cluster_data)*100):.1f}%\")\n",
    "        print()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PCA PARA VISUALIZA√á√ÉO 2D\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"üîÑ Reduzindo dimensionalidade com PCA...\")\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    df_ml['pca1'] = X_pca[:, 0]\n",
    "    df_ml['pca2'] = X_pca[:, 1]\n",
    "    \n",
    "    print(f\"‚úÖ Vari√¢ncia explicada: {pca.explained_variance_ratio_.sum()*100:.1f}%\")\n",
    "    \n",
    "    # Visualiza√ß√£o dos clusters\n",
    "    fig_clusters = go.Figure()\n",
    "    \n",
    "    colors_cluster = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    \n",
    "    for cluster_id in range(k_optimal):\n",
    "        cluster_data = df_ml[df_ml['cluster'] == cluster_id]\n",
    "        \n",
    "        fig_clusters.add_trace(go.Scatter(\n",
    "            x=cluster_data['pca1'],\n",
    "            y=cluster_data['pca2'],\n",
    "            mode='markers',\n",
    "            name=f'Cluster {cluster_id}',\n",
    "            marker=dict(\n",
    "                size=6,\n",
    "                color=colors_cluster[cluster_id],\n",
    "                opacity=0.6\n",
    "            ),\n",
    "            text=cluster_data['cnpj_raiz'],\n",
    "            hovertemplate='<b>Cluster %{fullData.name}</b><br>CNPJ: %{text}<br>PCA1: %{x:.2f}<br>PCA2: %{y:.2f}<extra></extra>'\n",
    "        ))\n",
    "    \n",
    "    # Centroides\n",
    "    centroids_pca = pca.transform(kmeans.cluster_centers_)\n",
    "    fig_clusters.add_trace(go.Scatter(\n",
    "        x=centroids_pca[:, 0],\n",
    "        y=centroids_pca[:, 1],\n",
    "        mode='markers',\n",
    "        name='Centroides',\n",
    "        marker=dict(\n",
    "            size=20,\n",
    "            color='black',\n",
    "            symbol='x',\n",
    "            line=dict(width=3, color='white')\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    fig_clusters.update_layout(\n",
    "        title='<b>Visualiza√ß√£o dos Clusters (PCA 2D)</b>',\n",
    "        xaxis_title=f'Componente Principal 1 ({pca.explained_variance_ratio_[0]*100:.1f}%)',\n",
    "        yaxis_title=f'Componente Principal 2 ({pca.explained_variance_ratio_[1]*100:.1f}%)',\n",
    "        height=600,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig_clusters.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PERFIL DOS CLUSTERS (Radar Chart)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüìä Gerando perfil dos clusters...\")\n",
    "    \n",
    "    fig_perfil = go.Figure()\n",
    "    \n",
    "    features_perfil = ['feat_rba_12m', 'feat_receita_mensal', 'feat_qtd_empresas_grupo', \n",
    "                       'feat_taxa_atividade']\n",
    "    df_perfil = df_ml.groupby('cluster')[features_perfil].mean()\n",
    "    \n",
    "    # Normalizar para visualiza√ß√£o (0-1)\n",
    "    df_perfil_norm = (df_perfil - df_perfil.min()) / (df_perfil.max() - df_perfil.min())\n",
    "    \n",
    "    for cluster_id in range(k_optimal):\n",
    "        fig_perfil.add_trace(go.Scatterpolar(\n",
    "            r=df_perfil_norm.loc[cluster_id].values,\n",
    "            theta=[f.replace('feat_', '').replace('_', ' ').title() for f in features_perfil],\n",
    "            fill='toself',\n",
    "            name=f'Cluster {cluster_id}',\n",
    "            line=dict(color=colors_cluster[cluster_id])\n",
    "        ))\n",
    "    \n",
    "    fig_perfil.update_layout(\n",
    "        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),\n",
    "        title='<b>Perfil dos Clusters (Normalizado)</b>',\n",
    "        height=500,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig_perfil.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DISTRIBUI√á√ÉO DE IRREGULARES POR CLUSTER\n",
    "    # ========================================================================\n",
    "    \n",
    "    cluster_irreg = df_ml.groupby('cluster')['target_irregular'].agg(['sum', 'count'])\n",
    "    cluster_irreg['perc'] = (cluster_irreg['sum'] / cluster_irreg['count']) * 100\n",
    "    \n",
    "    fig_cluster_irreg = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=[f'Cluster {i}' for i in range(k_optimal)],\n",
    "            y=cluster_irreg['perc'].values,\n",
    "            marker=dict(\n",
    "                color=cluster_irreg['perc'].values,\n",
    "                colorscale='Reds',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"% Irreg.\")\n",
    "            ),\n",
    "            text=[f'{x:.1f}%' for x in cluster_irreg['perc'].values],\n",
    "            textposition='outside'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig_cluster_irreg.update_layout(\n",
    "        title='<b>Percentual de Empresas Irregulares por Cluster</b>',\n",
    "        xaxis_title='Cluster',\n",
    "        yaxis_title='% de Empresas Irregulares',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig_cluster_irreg.show()\n",
    "    \n",
    "    print(f\"\\nüíæ Clusters salvos em df_ml['cluster']\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Dataset n√£o dispon√≠vel para clustering\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ CLUSTERING K-MEANS CONCLU√çDO!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe4bc0-5c5f-4654-8dec-5f40bdc86de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DASHBOARD FINAL - RESUMO EXECUTIVO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä DASHBOARD EXECUTIVO - RESUMO GERAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if df_ml is not None and len(df_ml) > 0:\n",
    "    \n",
    "    # ========================================================================\n",
    "    # M√âTRICAS CONSOLIDADAS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüéØ M√âTRICAS CONSOLIDADAS DO MODELO:\\n\")\n",
    "    \n",
    "    metrics_summary = pd.DataFrame({\n",
    "        'Modelo': ['Random Forest', 'XGBoost', 'Ensemble'],\n",
    "        'AUC-ROC': [auc_score, auc_xgb, auc_ensemble if 'auc_ensemble' in locals() else 0],\n",
    "        'Acur√°cia': [accuracy, accuracy_xgb, 0],\n",
    "        'Precis√£o': [precision, precision_xgb, 0],\n",
    "        'Recall': [recall, recall_xgb, 0],\n",
    "        'F1-Score': [f1, f1_xgb, 0]\n",
    "    })\n",
    "    \n",
    "    print(metrics_summary.to_string(index=False))\n",
    "    \n",
    "    # Gr√°fico de barras comparativo\n",
    "    fig_metrics = go.Figure()\n",
    "    \n",
    "    metrics_plot = ['AUC-ROC', 'Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score']\n",
    "    \n",
    "    for modelo in ['Random Forest', 'XGBoost']:\n",
    "        values = metrics_summary[metrics_summary['Modelo'] == modelo][metrics_plot].values[0]\n",
    "        \n",
    "        fig_metrics.add_trace(go.Bar(\n",
    "            name=modelo,\n",
    "            x=metrics_plot,\n",
    "            y=values,\n",
    "            text=[f'{v:.3f}' for v in values],\n",
    "            textposition='outside'\n",
    "        ))\n",
    "    \n",
    "    fig_metrics.update_layout(\n",
    "        title='<b>Compara√ß√£o de M√©tricas: Random Forest vs XGBoost</b>',\n",
    "        xaxis_title='M√©trica',\n",
    "        yaxis_title='Valor',\n",
    "        barmode='group',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig_metrics.show()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # RESUMO DOS CLUSTERS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüé≤ RESUMO DOS CLUSTERS:\\n\")\n",
    "    \n",
    "    cluster_summary = df_ml.groupby('cluster').agg({\n",
    "        'cnpj_raiz': 'count',\n",
    "        'feat_rba_12m': 'mean',\n",
    "        'feat_qtd_empresas_grupo': 'mean',\n",
    "        'target_irregular': lambda x: (x.sum() / len(x)) * 100\n",
    "    }).round(2)\n",
    "    \n",
    "    cluster_summary.columns = ['Qtd Empresas', 'RBA M√©dia', 'Emp/Grupo M√©dio', '% Irregular']\n",
    "    print(cluster_summary.to_string())\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TOP 20 EMPRESAS MAIS SUSPEITAS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\nüö® TOP 20 EMPRESAS MAIS SUSPEITAS (por Ensemble):\\n\")\n",
    "    \n",
    "    df_suspeitas = df_ml[df_ml['ensemble_probability'].notna()].copy()\n",
    "    df_suspeitas_top = df_suspeitas.nlargest(20, 'ensemble_probability')\n",
    "    \n",
    "    for idx, row in df_suspeitas_top.iterrows():\n",
    "        print(f\"{list(df_suspeitas_top.index).index(idx)+1:2d}. CNPJ: {row['cnpj_raiz']} | \"\n",
    "              f\"Prob: {row['ensemble_probability']:.3f} | \"\n",
    "              f\"Cluster: {int(row['cluster'])} | \"\n",
    "              f\"RBA: R$ {row['feat_rba_12m']:,.2f}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ An√°lise completa conclu√≠da!\")\n",
    "    print(f\"üíæ Resultados dispon√≠veis em: df_ml\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Dataset n√£o dispon√≠vel\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéâ AN√ÅLISE COMPLETA FINALIZADA!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Data Pipeline)",
   "language": "python",
   "name": "conda_data_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
